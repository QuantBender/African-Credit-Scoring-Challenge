{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from rgf.sklearn import RGFClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Train'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>tbl_loan_id</th>\n",
       "      <th>lender_id</th>\n",
       "      <th>loan_type</th>\n",
       "      <th>Total_Amount</th>\n",
       "      <th>Total_Amount_to_Repay</th>\n",
       "      <th>disbursement_date</th>\n",
       "      <th>due_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>New_versus_Repeat</th>\n",
       "      <th>Amount_Funded_By_Lender</th>\n",
       "      <th>Lender_portion_Funded</th>\n",
       "      <th>Lender_portion_to_be_repaid</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_266671248032267278</td>\n",
       "      <td>266671</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>248032</td>\n",
       "      <td>267278</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>8448.0</td>\n",
       "      <td>8448.0</td>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>2022-09-06</td>\n",
       "      <td>7</td>\n",
       "      <td>Repeat Loan</td>\n",
       "      <td>120.85</td>\n",
       "      <td>0.014305</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_248919228515267278</td>\n",
       "      <td>248919</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>228515</td>\n",
       "      <td>267278</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>25895.0</td>\n",
       "      <td>25979.0</td>\n",
       "      <td>2022-07-30</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>7</td>\n",
       "      <td>Repeat Loan</td>\n",
       "      <td>7768.50</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>7794.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_308486370501251804</td>\n",
       "      <td>308486</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>370501</td>\n",
       "      <td>251804</td>\n",
       "      <td>Type_7</td>\n",
       "      <td>6900.0</td>\n",
       "      <td>7142.0</td>\n",
       "      <td>2024-09-06</td>\n",
       "      <td>2024-09-13</td>\n",
       "      <td>7</td>\n",
       "      <td>Repeat Loan</td>\n",
       "      <td>1380.00</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_266004285009267278</td>\n",
       "      <td>266004</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>285009</td>\n",
       "      <td>267278</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>8958.0</td>\n",
       "      <td>9233.0</td>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>7</td>\n",
       "      <td>Repeat Loan</td>\n",
       "      <td>2687.40</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2770.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_253803305312267278</td>\n",
       "      <td>253803</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>305312</td>\n",
       "      <td>267278</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>4564.0</td>\n",
       "      <td>4728.0</td>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>7</td>\n",
       "      <td>Repeat Loan</td>\n",
       "      <td>1369.20</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID  customer_id country_id  tbl_loan_id  lender_id  \\\n",
       "0  ID_266671248032267278       266671      Kenya       248032     267278   \n",
       "1  ID_248919228515267278       248919      Kenya       228515     267278   \n",
       "2  ID_308486370501251804       308486      Kenya       370501     251804   \n",
       "3  ID_266004285009267278       266004      Kenya       285009     267278   \n",
       "4  ID_253803305312267278       253803      Kenya       305312     267278   \n",
       "\n",
       "  loan_type  Total_Amount  Total_Amount_to_Repay disbursement_date  \\\n",
       "0    Type_1        8448.0                 8448.0        2022-08-30   \n",
       "1    Type_1       25895.0                25979.0        2022-07-30   \n",
       "2    Type_7        6900.0                 7142.0        2024-09-06   \n",
       "3    Type_1        8958.0                 9233.0        2022-10-20   \n",
       "4    Type_1        4564.0                 4728.0        2022-11-28   \n",
       "\n",
       "     due_date  duration New_versus_Repeat  Amount_Funded_By_Lender  \\\n",
       "0  2022-09-06         7       Repeat Loan                   120.85   \n",
       "1  2022-08-06         7       Repeat Loan                  7768.50   \n",
       "2  2024-09-13         7       Repeat Loan                  1380.00   \n",
       "3  2022-10-27         7       Repeat Loan                  2687.40   \n",
       "4  2022-12-05         7       Repeat Loan                  1369.20   \n",
       "\n",
       "   Lender_portion_Funded  Lender_portion_to_be_repaid  target  \n",
       "0               0.014305                        121.0       0  \n",
       "1               0.300000                       7794.0       0  \n",
       "2               0.200000                       1428.0       0  \n",
       "3               0.300000                       2770.0       0  \n",
       "4               0.300000                       1418.0       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(68654, 16)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Test'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>tbl_loan_id</th>\n",
       "      <th>lender_id</th>\n",
       "      <th>loan_type</th>\n",
       "      <th>Total_Amount</th>\n",
       "      <th>Total_Amount_to_Repay</th>\n",
       "      <th>disbursement_date</th>\n",
       "      <th>due_date</th>\n",
       "      <th>duration</th>\n",
       "      <th>New_versus_Repeat</th>\n",
       "      <th>Amount_Funded_By_Lender</th>\n",
       "      <th>Lender_portion_Funded</th>\n",
       "      <th>Lender_portion_to_be_repaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_269404226088267278</td>\n",
       "      <td>269404</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>226088</td>\n",
       "      <td>267278</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>2022-07-27</td>\n",
       "      <td>2022-08-03</td>\n",
       "      <td>7</td>\n",
       "      <td>Repeat Loan</td>\n",
       "      <td>575.7</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_255356300042267278</td>\n",
       "      <td>255356</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>300042</td>\n",
       "      <td>267278</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>2138.0</td>\n",
       "      <td>2153.0</td>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>7</td>\n",
       "      <td>Repeat Loan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_257026243764267278</td>\n",
       "      <td>257026</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>243764</td>\n",
       "      <td>267278</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>8254.0</td>\n",
       "      <td>8304.0</td>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>7</td>\n",
       "      <td>Repeat Loan</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_264617299409267278</td>\n",
       "      <td>264617</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>299409</td>\n",
       "      <td>267278</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>3379.0</td>\n",
       "      <td>3379.0</td>\n",
       "      <td>2022-11-15</td>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>7</td>\n",
       "      <td>Repeat Loan</td>\n",
       "      <td>1013.7</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_247613296713267278</td>\n",
       "      <td>247613</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>296713</td>\n",
       "      <td>267278</td>\n",
       "      <td>Type_1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2022-11-10</td>\n",
       "      <td>2022-11-17</td>\n",
       "      <td>7</td>\n",
       "      <td>Repeat Loan</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID  customer_id country_id  tbl_loan_id  lender_id  \\\n",
       "0  ID_269404226088267278       269404      Kenya       226088     267278   \n",
       "1  ID_255356300042267278       255356      Kenya       300042     267278   \n",
       "2  ID_257026243764267278       257026      Kenya       243764     267278   \n",
       "3  ID_264617299409267278       264617      Kenya       299409     267278   \n",
       "4  ID_247613296713267278       247613      Kenya       296713     267278   \n",
       "\n",
       "  loan_type  Total_Amount  Total_Amount_to_Repay disbursement_date  \\\n",
       "0    Type_1        1919.0                 1989.0        2022-07-27   \n",
       "1    Type_1        2138.0                 2153.0        2022-11-16   \n",
       "2    Type_1        8254.0                 8304.0        2022-08-24   \n",
       "3    Type_1        3379.0                 3379.0        2022-11-15   \n",
       "4    Type_1         120.0                  120.0        2022-11-10   \n",
       "\n",
       "     due_date  duration New_versus_Repeat  Amount_Funded_By_Lender  \\\n",
       "0  2022-08-03         7       Repeat Loan                    575.7   \n",
       "1  2022-11-23         7       Repeat Loan                      0.0   \n",
       "2  2022-08-31         7       Repeat Loan                    207.0   \n",
       "3  2022-11-22         7       Repeat Loan                   1013.7   \n",
       "4  2022-11-17         7       Repeat Loan                     36.0   \n",
       "\n",
       "   Lender_portion_Funded  Lender_portion_to_be_repaid  \n",
       "0               0.300000                        597.0  \n",
       "1               0.000000                          0.0  \n",
       "2               0.025079                        208.0  \n",
       "3               0.300000                       1014.0  \n",
       "4               0.300000                         36.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(18594, 15)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the train dataset\n",
    "path=\"../Data/\"\n",
    "train = pd.read_csv(path+'Train.csv')\n",
    "test = pd.read_csv(path+'Test.csv')\n",
    "# Display the first few rows of the datasets and their shape\n",
    "display(\"Train\", train.head(), train.shape, \"Test\", test.head(), test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             68654\n",
       "customer_id                     6540\n",
       "country_id                         1\n",
       "tbl_loan_id                    66520\n",
       "lender_id                          4\n",
       "loan_type                         22\n",
       "Total_Amount                   19076\n",
       "Total_Amount_to_Repay          21920\n",
       "disbursement_date                768\n",
       "due_date                         893\n",
       "duration                          64\n",
       "New_versus_Repeat                  2\n",
       "Amount_Funded_By_Lender        23391\n",
       "Lender_portion_Funded          12844\n",
       "Lender_portion_to_be_repaid     9791\n",
       "target                             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             18594\n",
       "customer_id                     4962\n",
       "country_id                         2\n",
       "tbl_loan_id                    17067\n",
       "lender_id                          8\n",
       "loan_type                         22\n",
       "Total_Amount                    9372\n",
       "Total_Amount_to_Repay          10963\n",
       "disbursement_date                656\n",
       "due_date                         728\n",
       "duration                          50\n",
       "New_versus_Repeat                  2\n",
       "Amount_Funded_By_Lender         9704\n",
       "Lender_portion_Funded           3880\n",
       "Lender_portion_to_be_repaid     6782\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68654 entries, 0 to 68653\n",
      "Data columns (total 16 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   ID                           68654 non-null  object \n",
      " 1   customer_id                  68654 non-null  int64  \n",
      " 2   country_id                   68654 non-null  object \n",
      " 3   tbl_loan_id                  68654 non-null  int64  \n",
      " 4   lender_id                    68654 non-null  int64  \n",
      " 5   loan_type                    68654 non-null  object \n",
      " 6   Total_Amount                 68654 non-null  float64\n",
      " 7   Total_Amount_to_Repay        68654 non-null  float64\n",
      " 8   disbursement_date            68654 non-null  object \n",
      " 9   due_date                     68654 non-null  object \n",
      " 10  duration                     68654 non-null  int64  \n",
      " 11  New_versus_Repeat            68654 non-null  object \n",
      " 12  Amount_Funded_By_Lender      68654 non-null  float64\n",
      " 13  Lender_portion_Funded        68654 non-null  float64\n",
      " 14  Lender_portion_to_be_repaid  68654 non-null  float64\n",
      " 15  target                       68654 non-null  int64  \n",
      "dtypes: float64(5), int64(5), object(6)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID', 'customer_id', 'country_id', 'tbl_loan_id', 'lender_id']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in train.columns if \"_id\" in x.lower() or x.lower()==\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "New_versus_Repeat\n",
       "Repeat Loan    68087\n",
       "New Loan         567\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"New_versus_Repeat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing :\n",
    "    def __init__(self, train, test) :\n",
    "        self.train = train \n",
    "        self.test = test\n",
    "        self.train_shape = train.shape\n",
    "        self.test_shape = test.shape\n",
    "        self.train_columns = train.columns\n",
    "        self.test_columns = test.columns\n",
    "        self.id_cols = [x for x in train.columns if \"_id\" in x.lower() or x.lower()==\"id\"]\n",
    "        self.target_col = self.train.columns.difference(self.test.columns)\n",
    "        self.date_cols = [x for x in train.columns if \"date\" in x.lower()]\n",
    "        self.cat_cols = [x for x in train.columns if train[x].dtype==\"O\" and x not in self.id_cols and x not in self.date_cols]\n",
    "        self.num_cols = [x for x in train.columns if x not in self.cat_cols and x not in self.id_cols and x not in self.target_col and x not in self.date_cols]\n",
    "        self.test_ids = self.test[self.id_cols]\n",
    "        \n",
    "    \n",
    "    def all_data(self) :\n",
    "        return pd.concat([self.train, self.test], axis=0)   \n",
    "    \n",
    "    def drop_id_cols(self) :\n",
    "        self.train.drop(columns=self.id_cols, inplace=True)\n",
    "        self.test.drop(columns=self.id_cols, inplace=True)\n",
    "        return self.train, self.test\n",
    "    \n",
    "    def standardize(self) :\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        self.train[self.num_cols] = scaler.fit_transform(self.train[self.num_cols])\n",
    "        self.test[self.num_cols] = scaler.transform(self.test[self.num_cols])\n",
    "        return self.train, self.test\n",
    "    \n",
    "    def frequency_encoding_cat_cols(self) :\n",
    "        for col in self.cat_cols :\n",
    "            encoding = self.all_data()[col].value_counts()\n",
    "            self.train[col] = self.train[col].map(encoding)\n",
    "            self.test[col] = self.test[col].map(encoding)\n",
    "        return self.train, self.test\n",
    "    \n",
    "    def fillna(self) :\n",
    "        self.train.fillna(0, inplace=True)\n",
    "        self.test.fillna(0, inplace=True)\n",
    "        return self.train, self.test\n",
    "    \n",
    "    def feature_engineering_num_cols(self) :\n",
    "        for col in self.num_cols :\n",
    "            self.train[col+\"_squared\"] = self.train[col]**2\n",
    "            self.train[col+\"_cubed\"] = self.train[col]**3\n",
    "            self.train[col+\"_sqrt\"] = np.sqrt(self.train[col])\n",
    "            self.train[col+\"_log\"] = np.log(self.train[col]+1)\n",
    "            \n",
    "            self.test[col+\"_squared\"] = self.test[col]**2\n",
    "            self.test[col+\"_cubed\"] = self.test[col]**3\n",
    "            self.test[col+\"_sqrt\"] = np.sqrt(self.test[col])\n",
    "            self.test[col+\"_log\"] = np.log(self.test[col]+1)\n",
    "        return self.train, self.test\n",
    "    \n",
    "    def feature_engineering_date_cols(self) :\n",
    "        for col in self.date_cols :\n",
    "            self.train[col+\"_year\"] = pd.to_datetime(self.train[col]).dt.year\n",
    "            self.train[col+\"_month\"] = pd.to_datetime(self.train[col]).dt.month\n",
    "            self.train[col+\"_day\"] = pd.to_datetime(self.train[col]).dt.day\n",
    "            self.train[col+\"_dayofweek\"] = pd.to_datetime(self.train[col]).dt.dayofweek\n",
    "            self.train[col+\"_weekofyear\"] = pd.to_datetime(self.train[col]).dt.isocalendar().week\n",
    "            \n",
    "            self.test[col+\"_year\"] = pd.to_datetime(self.test[col]).dt.year\n",
    "            self.test[col+\"_month\"] = pd.to_datetime(self.test[col]).dt.month\n",
    "            self.test[col+\"_day\"] = pd.to_datetime(self.test[col]).dt.day\n",
    "            self.test[col+\"_dayofweek\"] = pd.to_datetime(self.test[col]).dt.dayofweek\n",
    "            self.test[col+\"_weekofyear\"] = pd.to_datetime(self.test[col]).dt.isocalendar().week\n",
    "            \n",
    "        self.train.drop(columns=self.date_cols, inplace=True)\n",
    "        self.test.drop(columns=self.date_cols, inplace=True)\n",
    "        \n",
    "        # ir mean by lender_id\n",
    "        self.train[\"ir_mean_by_disbursement_date_year\"] = self.train.groupby(\"disbursement_date_year\")[\"interest_rate\"].transform(\"mean\")\n",
    "        self.test[\"ir_mean_by_disbursement_date_year\"] = self.test.groupby(\"disbursement_date_year\")[\"interest_rate\"].transform(\"mean\")\n",
    "        \n",
    "        # ir variance by lender_id\n",
    "        self.train[\"ir_variance_by_disbursement_date_year\"] = self.train.groupby(\"disbursement_date_year\")[\"interest_rate\"].transform(\"var\")\n",
    "        self.test[\"ir_variance_by_disbursement_date_year\"] = self.test.groupby(\"disbursement_date_year\")[\"interest_rate\"].transform(\"var\")\n",
    "        \n",
    "        # ir skewness by lender_id\n",
    "        self.train[\"ir_skewness_by_disbursement_date_year\"] = self.train.groupby(\"disbursement_date_year\")[\"interest_rate\"].transform(\"skew\")\n",
    "        self.test[\"ir_skewness_by_disbursement_date_year\"] = self.test.groupby(\"disbursement_date_year\")[\"interest_rate\"].transform(\"skew\")\n",
    "        \n",
    "        # ir kurtosis by lender_id\n",
    "        self.train[\"ir_kurtosis_by_disbursement_date_year\"] = self.train.groupby(\"disbursement_date_year\")[\"interest_rate\"].apply(pd.Series.kurt)\n",
    "        self.test[\"ir_kurtosis_by_disbursement_date_year\"] = self.test.groupby(\"disbursement_date_year\")[\"interest_rate\"].apply(pd.Series.kurt)\n",
    "        \n",
    "        return self.train, self.test\n",
    "    \n",
    "    def credit_scoring_feature_engineering(self) :\n",
    "        # convert dates\n",
    "        for col in self.date_cols :\n",
    "            self.train[col] = pd.to_datetime(self.train[col])\n",
    "            self.test[col] = pd.to_datetime(self.test[col])\n",
    "        # loan amount ratio\n",
    "        self.train[\"loan_to_income\"] = self.train[\"Total_Amount\"]/self.train[\"Total_Amount_to_Repay\"]\n",
    "        self.test[\"loan_to_income\"] = self.test[\"Total_Amount\"]/self.test[\"Total_Amount_to_Repay\"]\n",
    "        # repayment duration in days\n",
    "        self.train[\"repayment_duration\"] = (self.train[\"due_date\"] - self.train[\"disbursement_date\"]).dt.days\n",
    "        self.test[\"repayment_duration\"] = (self.test[\"due_date\"] - self.test[\"disbursement_date\"]).dt.days\n",
    "        # lender funded ratio\n",
    "        self.train[\"lender_funded_ratio\"] = self.train[\"Amount_Funded_By_Lender\"]/self.train[\"Total_Amount\"]\n",
    "        self.test[\"lender_funded_ratio\"] = self.test[\"Amount_Funded_By_Lender\"]/self.test[\"Total_Amount\"]\n",
    "        \n",
    "        # loan to duration ratio\n",
    "        self.train[\"loan_to_duration_ratio\"] = self.train[\"Total_Amount\"]/self.train[\"repayment_duration\"]\n",
    "        self.test[\"loan_to_duration_ratio\"] = self.test[\"Total_Amount\"]/self.test[\"repayment_duration\"]\n",
    "        # lender portion ratio\n",
    "        self.train[\"lender_portion_ratio\"] = self.train[\"Lender_portion_Funded\"]/self.train[\"Total_Amount\"]\n",
    "        self.test[\"lender_portion_ratio\"] = self.test[\"Lender_portion_Funded\"]/self.test[\"Total_Amount\"]\n",
    "        # lender repayment ratio\n",
    "        self.train[\"lender_repayment_ratio\"] = self.train[\"Lender_portion_to_be_repaid\"]/self.train[\"Total_Amount_to_Repay\"]\n",
    "        self.test[\"lender_repayment_ratio\"] = self.test[\"Lender_portion_to_be_repaid\"]/self.test[\"Total_Amount_to_Repay\"]\n",
    "        # customer loan count \n",
    "        self.train[\"customer_loan_count\"] = self.train.groupby(\"customer_id\")[\"tbl_loan_id\"].transform(\"count\")\n",
    "        self.test[\"customer_loan_count\"] = self.test.groupby(\"customer_id\")[\"tbl_loan_id\"].transform(\"count\")\n",
    "        # average loan amount per customer\n",
    "        self.train[\"average_loan_amount_per_customer\"] = self.train.groupby(\"customer_id\")[\"Total_Amount\"].transform(\"mean\")\n",
    "        self.test[\"average_loan_amount_per_customer\"] = self.test.groupby(\"customer_id\")[\"Total_Amount\"].transform(\"mean\")\n",
    "        \n",
    "        # interest rate\n",
    "        self.train[\"interest_rate\"] = (self.train['Total_Amount_to_Repay'] - self.train['Total_Amount']) / self.train['Total_Amount']\n",
    "        self.test[\"interest_rate\"] = (self.test['Total_Amount_to_Repay'] - self.test['Total_Amount']) / self.test['Total_Amount']\n",
    "        \n",
    "        # ir mean by lender_id\n",
    "        self.train[\"ir_mean_by_lender_id\"] = self.train.groupby(\"lender_id\")[\"interest_rate\"].transform(\"mean\")\n",
    "        self.test[\"ir_mean_by_lender_id\"] = self.test.groupby(\"lender_id\")[\"interest_rate\"].transform(\"mean\")\n",
    "        \n",
    "        # ir variance by lender_id\n",
    "        self.train[\"ir_variance_by_lender_id\"] = self.train.groupby(\"lender_id\")[\"interest_rate\"].transform(\"var\")\n",
    "        self.test[\"ir_variance_by_lender_id\"] = self.test.groupby(\"lender_id\")[\"interest_rate\"].transform(\"var\")\n",
    "        \n",
    "        # ir skewness by lender_id\n",
    "        self.train[\"ir_skewness_by_lender_id\"] = self.train.groupby(\"lender_id\")[\"interest_rate\"].transform(\"skew\")\n",
    "        self.test[\"ir_skewness_by_lender_id\"] = self.test.groupby(\"lender_id\")[\"interest_rate\"].transform(\"skew\")\n",
    "        \n",
    "        # ir kurtosis by lender_id\n",
    "        self.train[\"ir_kurtosis_by_lender_id\"] = self.train.groupby(\"lender_id\")[\"interest_rate\"].apply(pd.Series.kurt)\n",
    "        self.test[\"ir_kurtosis_by_lender_id\"] = self.test.groupby(\"lender_id\")[\"interest_rate\"].apply(pd.Series.kurt)\n",
    "        \n",
    "        return self.train, self.test\n",
    "    \n",
    "    def feature_engineering(self) :\n",
    "        # self.feature_engineering_num_cols()\n",
    "        self.credit_scoring_feature_engineering()\n",
    "        self.feature_engineering_date_cols()\n",
    "        return self.train, self.test\n",
    "    \n",
    "    def replace_inf(self) :\n",
    "        self.train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        self.test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        return self.train, self.test\n",
    "    \n",
    "    def preprocess(self) :\n",
    "        self.feature_engineering()\n",
    "        self.drop_id_cols()\n",
    "        self.standardize()\n",
    "        self.frequency_encoding_cat_cols()\n",
    "        self.replace_inf()\n",
    "        self.fillna()\n",
    "        return self.train, self.test\n",
    "    \n",
    "preprocessor = Preprocessing(train, test)\n",
    "train, test = preprocessor.preprocess()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 68654 entries, 0 to 68653\n",
      "Data columns (total 36 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   loan_type                              68654 non-null  int64  \n",
      " 1   Total_Amount                           68654 non-null  float64\n",
      " 2   Total_Amount_to_Repay                  68654 non-null  float64\n",
      " 3   duration                               68654 non-null  float64\n",
      " 4   New_versus_Repeat                      68654 non-null  int64  \n",
      " 5   Amount_Funded_By_Lender                68654 non-null  float64\n",
      " 6   Lender_portion_Funded                  68654 non-null  float64\n",
      " 7   Lender_portion_to_be_repaid            68654 non-null  float64\n",
      " 8   target                                 68654 non-null  int64  \n",
      " 9   loan_to_income                         68654 non-null  float64\n",
      " 10  repayment_duration                     68654 non-null  int64  \n",
      " 11  lender_funded_ratio                    68654 non-null  float64\n",
      " 12  loan_to_duration_ratio                 68654 non-null  float64\n",
      " 13  lender_portion_ratio                   68654 non-null  float64\n",
      " 14  lender_repayment_ratio                 68654 non-null  float64\n",
      " 15  customer_loan_count                    68654 non-null  int64  \n",
      " 16  average_loan_amount_per_customer       68654 non-null  float64\n",
      " 17  interest_rate                          68654 non-null  float64\n",
      " 18  ir_mean_by_lender_id                   68654 non-null  float64\n",
      " 19  ir_variance_by_lender_id               68654 non-null  float64\n",
      " 20  ir_skewness_by_lender_id               68654 non-null  float64\n",
      " 21  ir_kurtosis_by_lender_id               68654 non-null  float64\n",
      " 22  disbursement_date_year                 68654 non-null  int32  \n",
      " 23  disbursement_date_month                68654 non-null  int32  \n",
      " 24  disbursement_date_day                  68654 non-null  int32  \n",
      " 25  disbursement_date_dayofweek            68654 non-null  int32  \n",
      " 26  disbursement_date_weekofyear           68654 non-null  UInt32 \n",
      " 27  due_date_year                          68654 non-null  int32  \n",
      " 28  due_date_month                         68654 non-null  int32  \n",
      " 29  due_date_day                           68654 non-null  int32  \n",
      " 30  due_date_dayofweek                     68654 non-null  int32  \n",
      " 31  due_date_weekofyear                    68654 non-null  UInt32 \n",
      " 32  ir_mean_by_disbursement_date_year      68654 non-null  float64\n",
      " 33  ir_variance_by_disbursement_date_year  68654 non-null  float64\n",
      " 34  ir_skewness_by_disbursement_date_year  68654 non-null  float64\n",
      " 35  ir_kurtosis_by_disbursement_date_year  68654 non-null  float64\n",
      "dtypes: UInt32(2), float64(21), int32(8), int64(5)\n",
      "memory usage: 16.4 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "due_date_year\n",
       "2022    64235\n",
       "2024     3102\n",
       "2023     1284\n",
       "2021       27\n",
       "2025        6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"due_date_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disbursement_date_year\n",
       "2022    64405\n",
       "2024     2970\n",
       "2023     1240\n",
       "2021       39\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"disbursement_date_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disbursement_date_year\n",
       "2022    17249\n",
       "2023      688\n",
       "2024      629\n",
       "2021       28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"disbursement_date_year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    67396\n",
       "1     1258\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\origin\\anaconda3\\Lib\\site-packages\\rgf\\utils.py:224: UserWarning: Cannot find FastRGF executable files. FastRGF estimators will be unavailable for usage.\n",
      "  warnings.warn(\"Cannot find FastRGF executable files. \"\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=98)\n",
    "models = {\n",
    "    \"LogisticRegression\" : LogisticRegression(max_iter=1000000),\n",
    "    \"RandomForest\" : RandomForestClassifier(),\n",
    "    \"SVC\" : SVC(),\n",
    "    \"KNeighbors\" : KNeighborsClassifier(),\n",
    "    \"DecisionTree\" : DecisionTreeClassifier(),\n",
    "    \"LGBM\" : LGBMClassifier(),\n",
    "    \"XGB\" : XGBClassifier(),\n",
    "    \"CatBoost\" : CatBoostClassifier(),\n",
    "    \"RGF\" : RGFClassifier(),\n",
    "    \"GradientBoosting\" : GradientBoostingClassifier(),\n",
    "    \"AdaBoost\" : AdaBoostClassifier(),\n",
    "    \"ExtraTrees\" : ExtraTreesClassifier(),\n",
    "    \"Bagging\" : BaggingClassifier(),\n",
    "    \"Voting\" : VotingClassifier(estimators=[(\"lgbm\", LGBMClassifier()), (\"xgb\", XGBClassifier()), (\"cat\", CatBoostClassifier()),\n",
    "                                             (\"rgf\", RGFClassifier()), (\"rf\", RandomForestClassifier())]),\n",
    "    \"Stacking\" : StackingClassifier(estimators=[(\"lgbm\", LGBMClassifier()), (\"xgb\", XGBClassifier()), (\"cat\", CatBoostClassifier()),\n",
    "                                             (\"rgf\", RGFClassifier()), (\"rf\", RandomForestClassifier())])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68654, 36)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs1 = EFS(models[\"RandomForest\"], \n",
    "           min_features=15,\n",
    "           max_features=25,\n",
    "           scoring='f1',\n",
    "           print_progress=True,\n",
    "           cv=skf)\n",
    "\n",
    "efs1 = efs1.fit(train.drop(columns=\"target\"), train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best f1 score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)\n",
    "print('Best subset (corresponding names):', efs1.best_feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBenchmarching:\n",
    "    def __init__(self, models, cv, train, test):\n",
    "        self.models = models\n",
    "        self.cv = cv\n",
    "        self.results = {}\n",
    "        self.train = train\n",
    "        self.X = self.train.drop(columns=\"target\")\n",
    "        self.y = self.train.target\n",
    "        self.X_test = test[self.X.columns]\n",
    "        self.skf = StratifiedKFold(n_splits=self.cv, shuffle=True, random_state=98)\n",
    "        \n",
    "    def fit(self):\n",
    "        for name, model in self.models.items():\n",
    "            accuracy = []\n",
    "            f1 = []\n",
    "            precision = []\n",
    "            recall = []\n",
    "            roc = []\n",
    "            for train_idx, test_idx in self.skf.split(self.X, self.y):\n",
    "                X_train, X_test = self.X.iloc[train_idx], self.X.iloc[test_idx]\n",
    "                y_train, y_test = self.y.iloc[train_idx], self.y.iloc[test_idx]\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                accuracy.append(accuracy_score(y_test, y_pred))\n",
    "                f1.append(f1_score(y_test, y_pred))\n",
    "                precision.append(precision_score(y_test, y_pred))\n",
    "                recall.append(recall_score(y_test, y_pred))\n",
    "                roc.append(roc_auc_score(y_test, y_pred))\n",
    "            self.results[name] = {\n",
    "                \"accuracy\" : np.mean(accuracy),\n",
    "                \"f1\" : np.mean(f1),\n",
    "                \"precision\" : np.mean(precision),\n",
    "                \"recall\" : np.mean(recall),\n",
    "                \"roc\" : np.mean(roc)\n",
    "            }\n",
    "        return self.results\n",
    "    \n",
    "    def plot_results(self):\n",
    "        results = pd.DataFrame(self.results)\n",
    "        results.plot(kind=\"bar\", figsize=(15, 6))\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.show()\n",
    "        \n",
    "    def predict(self):\n",
    "        for name, model in self.models.items():\n",
    "            model.fit(self.X, self.y)\n",
    "            self.X_test[\"target\"] = model.predict(self.X_test)\n",
    "            self.X_test[\"ID\"] = preprocessor.test_ids[\"ID\"]\n",
    "            self.X_test[[\"ID\", \"target\"]].to_csv(f\"{name}.csv\", index=False)\n",
    "            self.X_test.drop(columns=[\"ID\", \"target\"], inplace=True)\n",
    "    \n",
    "    def ensembling_top_5_f1(self):\n",
    "        models = list(self.results.keys())\n",
    "        models = sorted(models, key=lambda x: self.results[x][\"f1\"], reverse=True)[:5]\n",
    "        for name in models:\n",
    "            model = self.models[name]\n",
    "            model.fit(self.X, self.y)\n",
    "            self.X_test[\"target\"] = model.predict(self.X_test)\n",
    "            self.X_test[\"ID\"] = preprocessor.test_ids[\"ID\"]\n",
    "            self.X_test[[\"ID\", \"target\"]].to_csv(f\"../Submissions/{name}.csv\", index=False)\n",
    "            self.X_test.drop(columns=[\"ID\", \"target\"], inplace=True)\n",
    "    \n",
    "    def cross_val_predict_top_3_f1(self):\n",
    "        models = list(self.results.keys())\n",
    "        models = sorted(models, key=lambda x: self.results[x][\"f1\"], reverse=True)[:3]\n",
    "        for name in models:\n",
    "            model = self.models[name]\n",
    "            y_preds = np.zeros(self.X_test.shape[0])\n",
    "            for train_idx, test_idx in self.skf.split(self.X, self.y):\n",
    "                X_train, X_test = self.X.iloc[train_idx], self.X.iloc[test_idx]\n",
    "                y_train, y_test = self.y.iloc[train_idx], self.y.iloc[test_idx]\n",
    "                model.fit(X_train, y_train)\n",
    "                y_preds += model.predict(self.X_test)\n",
    "            self.X_test[\"target\"] = y_preds/self.cv\n",
    "            self.X_test[\"ID\"] = preprocessor.test_ids[\"ID\"]\n",
    "            self.X_test[[\"ID\", \"target\"]].to_csv(f\"../Submissions/crossval_{name}.csv\", index=False)\n",
    "            self.X_test.drop(columns=[\"ID\", \"target\"], inplace=True)\n",
    "        \n",
    "    def average_top_5_f1(self):\n",
    "        models = list(self.results.keys())\n",
    "        models = sorted(models, key=lambda x: self.results[x][\"f1\"], reverse=True)[:5]\n",
    "        averages = np.zeros(self.X_test.shape[0])\n",
    "        for name in models:\n",
    "            model = self.models[name]\n",
    "            model.fit(self.X, self.y)\n",
    "            averages += model.predict(self.X_test)\n",
    "        self.X_test[\"target\"] = averages/5\n",
    "        self.X_test[\"ID\"] = preprocessor.test_ids[\"ID\"]\n",
    "        self.X_test[[\"ID\", \"target\"]].to_csv(\"../Submissions/average_top_5_f1.csv\", index=False)\n",
    "        self.X_test.drop(columns=[\"ID\", \"target\"], inplace=True)\n",
    "            \n",
    "    \n",
    "model_benchmarching = ModelBenchmarching(models, 5, train, test)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\origin\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_benchmarching.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_benchmarching.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1007, number of negative: 53916\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8736\n",
      "[LightGBM] [Info] Number of data points in the train set: 54923, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018335 -> initscore=-3.980452\n",
      "[LightGBM] [Info] Start training from score -3.980452\n",
      "[LightGBM] [Info] Number of positive: 1006, number of negative: 53917\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8731\n",
      "[LightGBM] [Info] Number of data points in the train set: 54923, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018317 -> initscore=-3.981464\n",
      "[LightGBM] [Info] Start training from score -3.981464\n",
      "[LightGBM] [Info] Number of positive: 1006, number of negative: 53917\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8723\n",
      "[LightGBM] [Info] Number of data points in the train set: 54923, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018317 -> initscore=-3.981464\n",
      "[LightGBM] [Info] Start training from score -3.981464\n",
      "[LightGBM] [Info] Number of positive: 1006, number of negative: 53917\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8739\n",
      "[LightGBM] [Info] Number of data points in the train set: 54923, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018317 -> initscore=-3.981464\n",
      "[LightGBM] [Info] Start training from score -3.981464\n",
      "[LightGBM] [Info] Number of positive: 1007, number of negative: 53917\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8745\n",
      "[LightGBM] [Info] Number of data points in the train set: 54924, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018334 -> initscore=-3.980470\n",
      "[LightGBM] [Info] Start training from score -3.980470\n"
     ]
    }
   ],
   "source": [
    "model_benchmarching.cross_val_predict_top_3_f1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.062689\n",
      "0:\tlearn: 0.4816766\ttotal: 23.2ms\tremaining: 23.2s\n",
      "1:\tlearn: 0.3795851\ttotal: 46.3ms\tremaining: 23.1s\n",
      "2:\tlearn: 0.2810576\ttotal: 63.4ms\tremaining: 21.1s\n",
      "3:\tlearn: 0.2030641\ttotal: 81.3ms\tremaining: 20.2s\n",
      "4:\tlearn: 0.1519495\ttotal: 99.6ms\tremaining: 19.8s\n",
      "5:\tlearn: 0.1138970\ttotal: 118ms\tremaining: 19.5s\n",
      "6:\tlearn: 0.0880194\ttotal: 138ms\tremaining: 19.6s\n",
      "7:\tlearn: 0.0707859\ttotal: 160ms\tremaining: 19.8s\n",
      "8:\tlearn: 0.0579787\ttotal: 178ms\tremaining: 19.6s\n",
      "9:\tlearn: 0.0488617\ttotal: 197ms\tremaining: 19.5s\n",
      "10:\tlearn: 0.0427116\ttotal: 216ms\tremaining: 19.4s\n",
      "11:\tlearn: 0.0383567\ttotal: 237ms\tremaining: 19.5s\n",
      "12:\tlearn: 0.0351152\ttotal: 257ms\tremaining: 19.5s\n",
      "13:\tlearn: 0.0322762\ttotal: 277ms\tremaining: 19.5s\n",
      "14:\tlearn: 0.0304869\ttotal: 297ms\tremaining: 19.5s\n",
      "15:\tlearn: 0.0287713\ttotal: 321ms\tremaining: 19.7s\n",
      "16:\tlearn: 0.0272813\ttotal: 340ms\tremaining: 19.6s\n",
      "17:\tlearn: 0.0253679\ttotal: 359ms\tremaining: 19.6s\n",
      "18:\tlearn: 0.0243217\ttotal: 379ms\tremaining: 19.6s\n",
      "19:\tlearn: 0.0232988\ttotal: 399ms\tremaining: 19.6s\n",
      "20:\tlearn: 0.0225625\ttotal: 423ms\tremaining: 19.7s\n",
      "21:\tlearn: 0.0219483\ttotal: 447ms\tremaining: 19.9s\n",
      "22:\tlearn: 0.0215821\ttotal: 470ms\tremaining: 20s\n",
      "23:\tlearn: 0.0209758\ttotal: 498ms\tremaining: 20.3s\n",
      "24:\tlearn: 0.0206709\ttotal: 519ms\tremaining: 20.3s\n",
      "25:\tlearn: 0.0204801\ttotal: 539ms\tremaining: 20.2s\n",
      "26:\tlearn: 0.0203140\ttotal: 559ms\tremaining: 20.1s\n",
      "27:\tlearn: 0.0198225\ttotal: 580ms\tremaining: 20.1s\n",
      "28:\tlearn: 0.0195240\ttotal: 600ms\tremaining: 20.1s\n",
      "29:\tlearn: 0.0191814\ttotal: 623ms\tremaining: 20.2s\n",
      "30:\tlearn: 0.0188683\ttotal: 646ms\tremaining: 20.2s\n",
      "31:\tlearn: 0.0188054\ttotal: 672ms\tremaining: 20.3s\n",
      "32:\tlearn: 0.0184977\ttotal: 693ms\tremaining: 20.3s\n",
      "33:\tlearn: 0.0183804\ttotal: 714ms\tremaining: 20.3s\n",
      "34:\tlearn: 0.0180711\ttotal: 735ms\tremaining: 20.3s\n",
      "35:\tlearn: 0.0179492\ttotal: 754ms\tremaining: 20.2s\n",
      "36:\tlearn: 0.0178530\ttotal: 777ms\tremaining: 20.2s\n",
      "37:\tlearn: 0.0177659\ttotal: 797ms\tremaining: 20.2s\n",
      "38:\tlearn: 0.0173387\ttotal: 822ms\tremaining: 20.2s\n",
      "39:\tlearn: 0.0170142\ttotal: 851ms\tremaining: 20.4s\n",
      "40:\tlearn: 0.0167472\ttotal: 872ms\tremaining: 20.4s\n",
      "41:\tlearn: 0.0166659\ttotal: 893ms\tremaining: 20.4s\n",
      "42:\tlearn: 0.0165667\ttotal: 913ms\tremaining: 20.3s\n",
      "43:\tlearn: 0.0164471\ttotal: 934ms\tremaining: 20.3s\n",
      "44:\tlearn: 0.0161458\ttotal: 958ms\tremaining: 20.3s\n",
      "45:\tlearn: 0.0159476\ttotal: 981ms\tremaining: 20.4s\n",
      "46:\tlearn: 0.0156843\ttotal: 1.01s\tremaining: 20.5s\n",
      "47:\tlearn: 0.0156266\ttotal: 1.03s\tremaining: 20.5s\n",
      "48:\tlearn: 0.0155550\ttotal: 1.06s\tremaining: 20.6s\n",
      "49:\tlearn: 0.0152990\ttotal: 1.09s\tremaining: 20.7s\n",
      "50:\tlearn: 0.0152545\ttotal: 1.12s\tremaining: 20.8s\n",
      "51:\tlearn: 0.0150748\ttotal: 1.15s\tremaining: 20.9s\n",
      "52:\tlearn: 0.0150459\ttotal: 1.17s\tremaining: 21s\n",
      "53:\tlearn: 0.0149627\ttotal: 1.2s\tremaining: 21s\n",
      "54:\tlearn: 0.0147720\ttotal: 1.23s\tremaining: 21.1s\n",
      "55:\tlearn: 0.0145881\ttotal: 1.25s\tremaining: 21.1s\n",
      "56:\tlearn: 0.0145009\ttotal: 1.27s\tremaining: 21.1s\n",
      "57:\tlearn: 0.0143783\ttotal: 1.3s\tremaining: 21.1s\n",
      "58:\tlearn: 0.0142276\ttotal: 1.32s\tremaining: 21.1s\n",
      "59:\tlearn: 0.0140758\ttotal: 1.34s\tremaining: 21.1s\n",
      "60:\tlearn: 0.0140520\ttotal: 1.37s\tremaining: 21.1s\n",
      "61:\tlearn: 0.0140248\ttotal: 1.39s\tremaining: 21.1s\n",
      "62:\tlearn: 0.0138842\ttotal: 1.42s\tremaining: 21.1s\n",
      "63:\tlearn: 0.0137366\ttotal: 1.44s\tremaining: 21.1s\n",
      "64:\tlearn: 0.0136100\ttotal: 1.46s\tremaining: 21.1s\n",
      "65:\tlearn: 0.0134750\ttotal: 1.49s\tremaining: 21s\n",
      "66:\tlearn: 0.0134315\ttotal: 1.51s\tremaining: 21s\n",
      "67:\tlearn: 0.0134138\ttotal: 1.53s\tremaining: 21.1s\n",
      "68:\tlearn: 0.0133347\ttotal: 1.56s\tremaining: 21.1s\n",
      "69:\tlearn: 0.0133164\ttotal: 1.58s\tremaining: 21s\n",
      "70:\tlearn: 0.0132574\ttotal: 1.61s\tremaining: 21s\n",
      "71:\tlearn: 0.0132280\ttotal: 1.63s\tremaining: 21s\n",
      "72:\tlearn: 0.0131625\ttotal: 1.65s\tremaining: 21s\n",
      "73:\tlearn: 0.0130439\ttotal: 1.67s\tremaining: 20.9s\n",
      "74:\tlearn: 0.0129495\ttotal: 1.7s\tremaining: 20.9s\n",
      "75:\tlearn: 0.0128573\ttotal: 1.73s\tremaining: 21s\n",
      "76:\tlearn: 0.0128128\ttotal: 1.75s\tremaining: 21s\n",
      "77:\tlearn: 0.0127302\ttotal: 1.77s\tremaining: 21s\n",
      "78:\tlearn: 0.0127120\ttotal: 1.79s\tremaining: 20.9s\n",
      "79:\tlearn: 0.0126349\ttotal: 1.81s\tremaining: 20.9s\n",
      "80:\tlearn: 0.0125962\ttotal: 1.84s\tremaining: 20.8s\n",
      "81:\tlearn: 0.0125757\ttotal: 1.86s\tremaining: 20.8s\n",
      "82:\tlearn: 0.0125246\ttotal: 1.89s\tremaining: 20.9s\n",
      "83:\tlearn: 0.0124894\ttotal: 1.91s\tremaining: 20.8s\n",
      "84:\tlearn: 0.0124240\ttotal: 1.93s\tremaining: 20.8s\n",
      "85:\tlearn: 0.0123225\ttotal: 1.96s\tremaining: 20.8s\n",
      "86:\tlearn: 0.0122662\ttotal: 1.98s\tremaining: 20.8s\n",
      "87:\tlearn: 0.0121566\ttotal: 2s\tremaining: 20.7s\n",
      "88:\tlearn: 0.0120945\ttotal: 2.02s\tremaining: 20.7s\n",
      "89:\tlearn: 0.0120552\ttotal: 2.05s\tremaining: 20.8s\n",
      "90:\tlearn: 0.0119910\ttotal: 2.08s\tremaining: 20.8s\n",
      "91:\tlearn: 0.0119195\ttotal: 2.1s\tremaining: 20.7s\n",
      "92:\tlearn: 0.0118834\ttotal: 2.12s\tremaining: 20.7s\n",
      "93:\tlearn: 0.0118374\ttotal: 2.15s\tremaining: 20.7s\n",
      "94:\tlearn: 0.0118237\ttotal: 2.18s\tremaining: 20.7s\n",
      "95:\tlearn: 0.0117751\ttotal: 2.2s\tremaining: 20.8s\n",
      "96:\tlearn: 0.0117604\ttotal: 2.23s\tremaining: 20.8s\n",
      "97:\tlearn: 0.0117311\ttotal: 2.27s\tremaining: 20.9s\n",
      "98:\tlearn: 0.0116914\ttotal: 2.3s\tremaining: 20.9s\n",
      "99:\tlearn: 0.0116364\ttotal: 2.32s\tremaining: 20.9s\n",
      "100:\tlearn: 0.0115677\ttotal: 2.34s\tremaining: 20.9s\n",
      "101:\tlearn: 0.0115360\ttotal: 2.37s\tremaining: 20.9s\n",
      "102:\tlearn: 0.0114724\ttotal: 2.39s\tremaining: 20.8s\n",
      "103:\tlearn: 0.0114300\ttotal: 2.42s\tremaining: 20.8s\n",
      "104:\tlearn: 0.0113974\ttotal: 2.45s\tremaining: 20.9s\n",
      "105:\tlearn: 0.0113537\ttotal: 2.47s\tremaining: 20.8s\n",
      "106:\tlearn: 0.0113278\ttotal: 2.5s\tremaining: 20.8s\n",
      "107:\tlearn: 0.0112705\ttotal: 2.52s\tremaining: 20.8s\n",
      "108:\tlearn: 0.0112354\ttotal: 2.55s\tremaining: 20.8s\n",
      "109:\tlearn: 0.0111852\ttotal: 2.57s\tremaining: 20.8s\n",
      "110:\tlearn: 0.0111262\ttotal: 2.6s\tremaining: 20.8s\n",
      "111:\tlearn: 0.0110858\ttotal: 2.63s\tremaining: 20.9s\n",
      "112:\tlearn: 0.0110739\ttotal: 2.66s\tremaining: 20.9s\n",
      "113:\tlearn: 0.0110374\ttotal: 2.68s\tremaining: 20.8s\n",
      "114:\tlearn: 0.0110007\ttotal: 2.7s\tremaining: 20.8s\n",
      "115:\tlearn: 0.0109780\ttotal: 2.73s\tremaining: 20.8s\n",
      "116:\tlearn: 0.0109341\ttotal: 2.75s\tremaining: 20.7s\n",
      "117:\tlearn: 0.0109176\ttotal: 2.77s\tremaining: 20.7s\n",
      "118:\tlearn: 0.0108873\ttotal: 2.8s\tremaining: 20.7s\n",
      "119:\tlearn: 0.0108549\ttotal: 2.82s\tremaining: 20.7s\n",
      "120:\tlearn: 0.0108345\ttotal: 2.84s\tremaining: 20.7s\n",
      "121:\tlearn: 0.0108093\ttotal: 2.86s\tremaining: 20.6s\n",
      "122:\tlearn: 0.0107910\ttotal: 2.89s\tremaining: 20.6s\n",
      "123:\tlearn: 0.0107337\ttotal: 2.91s\tremaining: 20.6s\n",
      "124:\tlearn: 0.0107258\ttotal: 2.93s\tremaining: 20.5s\n",
      "125:\tlearn: 0.0106922\ttotal: 2.96s\tremaining: 20.5s\n",
      "126:\tlearn: 0.0106667\ttotal: 2.98s\tremaining: 20.5s\n",
      "127:\tlearn: 0.0105831\ttotal: 3.01s\tremaining: 20.5s\n",
      "128:\tlearn: 0.0105114\ttotal: 3.03s\tremaining: 20.5s\n",
      "129:\tlearn: 0.0104925\ttotal: 3.05s\tremaining: 20.4s\n",
      "130:\tlearn: 0.0104799\ttotal: 3.08s\tremaining: 20.4s\n",
      "131:\tlearn: 0.0104355\ttotal: 3.1s\tremaining: 20.4s\n",
      "132:\tlearn: 0.0104262\ttotal: 3.12s\tremaining: 20.3s\n",
      "133:\tlearn: 0.0104031\ttotal: 3.15s\tremaining: 20.3s\n",
      "134:\tlearn: 0.0103817\ttotal: 3.17s\tremaining: 20.3s\n",
      "135:\tlearn: 0.0103451\ttotal: 3.2s\tremaining: 20.3s\n",
      "136:\tlearn: 0.0103003\ttotal: 3.22s\tremaining: 20.3s\n",
      "137:\tlearn: 0.0102712\ttotal: 3.25s\tremaining: 20.3s\n",
      "138:\tlearn: 0.0102328\ttotal: 3.27s\tremaining: 20.3s\n",
      "139:\tlearn: 0.0102133\ttotal: 3.3s\tremaining: 20.3s\n",
      "140:\tlearn: 0.0101616\ttotal: 3.33s\tremaining: 20.3s\n",
      "141:\tlearn: 0.0101151\ttotal: 3.37s\tremaining: 20.4s\n",
      "142:\tlearn: 0.0100953\ttotal: 3.41s\tremaining: 20.5s\n",
      "143:\tlearn: 0.0100462\ttotal: 3.44s\tremaining: 20.5s\n",
      "144:\tlearn: 0.0100245\ttotal: 3.48s\tremaining: 20.5s\n",
      "145:\tlearn: 0.0099863\ttotal: 3.51s\tremaining: 20.5s\n",
      "146:\tlearn: 0.0099017\ttotal: 3.54s\tremaining: 20.5s\n",
      "147:\tlearn: 0.0098817\ttotal: 3.56s\tremaining: 20.5s\n",
      "148:\tlearn: 0.0098540\ttotal: 3.6s\tremaining: 20.6s\n",
      "149:\tlearn: 0.0098266\ttotal: 3.63s\tremaining: 20.6s\n",
      "150:\tlearn: 0.0097734\ttotal: 3.67s\tremaining: 20.6s\n",
      "151:\tlearn: 0.0097540\ttotal: 3.69s\tremaining: 20.6s\n",
      "152:\tlearn: 0.0096986\ttotal: 3.72s\tremaining: 20.6s\n",
      "153:\tlearn: 0.0096519\ttotal: 3.75s\tremaining: 20.6s\n",
      "154:\tlearn: 0.0096245\ttotal: 3.78s\tremaining: 20.6s\n",
      "155:\tlearn: 0.0095887\ttotal: 3.8s\tremaining: 20.6s\n",
      "156:\tlearn: 0.0095475\ttotal: 3.83s\tremaining: 20.6s\n",
      "157:\tlearn: 0.0095055\ttotal: 3.86s\tremaining: 20.6s\n",
      "158:\tlearn: 0.0094869\ttotal: 3.88s\tremaining: 20.5s\n",
      "159:\tlearn: 0.0094371\ttotal: 3.91s\tremaining: 20.5s\n",
      "160:\tlearn: 0.0094247\ttotal: 3.94s\tremaining: 20.5s\n",
      "161:\tlearn: 0.0093957\ttotal: 3.96s\tremaining: 20.5s\n",
      "162:\tlearn: 0.0093734\ttotal: 3.99s\tremaining: 20.5s\n",
      "163:\tlearn: 0.0093666\ttotal: 4.02s\tremaining: 20.5s\n",
      "164:\tlearn: 0.0093232\ttotal: 4.06s\tremaining: 20.5s\n",
      "165:\tlearn: 0.0093129\ttotal: 4.08s\tremaining: 20.5s\n",
      "166:\tlearn: 0.0092732\ttotal: 4.11s\tremaining: 20.5s\n",
      "167:\tlearn: 0.0092474\ttotal: 4.13s\tremaining: 20.5s\n",
      "168:\tlearn: 0.0091962\ttotal: 4.17s\tremaining: 20.5s\n",
      "169:\tlearn: 0.0091865\ttotal: 4.19s\tremaining: 20.5s\n",
      "170:\tlearn: 0.0091001\ttotal: 4.22s\tremaining: 20.4s\n",
      "171:\tlearn: 0.0090916\ttotal: 4.25s\tremaining: 20.5s\n",
      "172:\tlearn: 0.0090866\ttotal: 4.27s\tremaining: 20.4s\n",
      "173:\tlearn: 0.0090427\ttotal: 4.3s\tremaining: 20.4s\n",
      "174:\tlearn: 0.0090264\ttotal: 4.32s\tremaining: 20.4s\n",
      "175:\tlearn: 0.0090159\ttotal: 4.34s\tremaining: 20.3s\n",
      "176:\tlearn: 0.0089916\ttotal: 4.37s\tremaining: 20.3s\n",
      "177:\tlearn: 0.0089805\ttotal: 4.4s\tremaining: 20.3s\n",
      "178:\tlearn: 0.0089598\ttotal: 4.43s\tremaining: 20.3s\n",
      "179:\tlearn: 0.0089497\ttotal: 4.46s\tremaining: 20.3s\n",
      "180:\tlearn: 0.0089381\ttotal: 4.5s\tremaining: 20.3s\n",
      "181:\tlearn: 0.0089063\ttotal: 4.53s\tremaining: 20.3s\n",
      "182:\tlearn: 0.0088857\ttotal: 4.55s\tremaining: 20.3s\n",
      "183:\tlearn: 0.0088624\ttotal: 4.59s\tremaining: 20.4s\n",
      "184:\tlearn: 0.0088365\ttotal: 4.63s\tremaining: 20.4s\n",
      "185:\tlearn: 0.0088100\ttotal: 4.67s\tremaining: 20.4s\n",
      "186:\tlearn: 0.0088023\ttotal: 4.7s\tremaining: 20.4s\n",
      "187:\tlearn: 0.0087764\ttotal: 4.74s\tremaining: 20.5s\n",
      "188:\tlearn: 0.0087637\ttotal: 4.77s\tremaining: 20.5s\n",
      "189:\tlearn: 0.0087438\ttotal: 4.8s\tremaining: 20.5s\n",
      "190:\tlearn: 0.0087249\ttotal: 4.83s\tremaining: 20.5s\n",
      "191:\tlearn: 0.0087057\ttotal: 4.87s\tremaining: 20.5s\n",
      "192:\tlearn: 0.0086686\ttotal: 4.9s\tremaining: 20.5s\n",
      "193:\tlearn: 0.0086459\ttotal: 4.93s\tremaining: 20.5s\n",
      "194:\tlearn: 0.0086345\ttotal: 4.96s\tremaining: 20.5s\n",
      "195:\tlearn: 0.0086226\ttotal: 4.98s\tremaining: 20.4s\n",
      "196:\tlearn: 0.0086142\ttotal: 5.01s\tremaining: 20.4s\n",
      "197:\tlearn: 0.0085884\ttotal: 5.04s\tremaining: 20.4s\n",
      "198:\tlearn: 0.0085716\ttotal: 5.07s\tremaining: 20.4s\n",
      "199:\tlearn: 0.0085480\ttotal: 5.1s\tremaining: 20.4s\n",
      "200:\tlearn: 0.0085388\ttotal: 5.13s\tremaining: 20.4s\n",
      "201:\tlearn: 0.0085018\ttotal: 5.16s\tremaining: 20.4s\n",
      "202:\tlearn: 0.0084807\ttotal: 5.19s\tremaining: 20.4s\n",
      "203:\tlearn: 0.0084744\ttotal: 5.21s\tremaining: 20.3s\n",
      "204:\tlearn: 0.0084648\ttotal: 5.24s\tremaining: 20.3s\n",
      "205:\tlearn: 0.0084589\ttotal: 5.27s\tremaining: 20.3s\n",
      "206:\tlearn: 0.0084373\ttotal: 5.29s\tremaining: 20.3s\n",
      "207:\tlearn: 0.0084166\ttotal: 5.32s\tremaining: 20.2s\n",
      "208:\tlearn: 0.0083828\ttotal: 5.34s\tremaining: 20.2s\n",
      "209:\tlearn: 0.0083558\ttotal: 5.37s\tremaining: 20.2s\n",
      "210:\tlearn: 0.0083339\ttotal: 5.4s\tremaining: 20.2s\n",
      "211:\tlearn: 0.0083241\ttotal: 5.42s\tremaining: 20.1s\n",
      "212:\tlearn: 0.0082942\ttotal: 5.44s\tremaining: 20.1s\n",
      "213:\tlearn: 0.0082653\ttotal: 5.47s\tremaining: 20.1s\n",
      "214:\tlearn: 0.0082559\ttotal: 5.49s\tremaining: 20.1s\n",
      "215:\tlearn: 0.0082020\ttotal: 5.52s\tremaining: 20s\n",
      "216:\tlearn: 0.0081730\ttotal: 5.56s\tremaining: 20.1s\n",
      "217:\tlearn: 0.0081501\ttotal: 5.6s\tremaining: 20.1s\n",
      "218:\tlearn: 0.0081223\ttotal: 5.63s\tremaining: 20.1s\n",
      "219:\tlearn: 0.0081018\ttotal: 5.65s\tremaining: 20s\n",
      "220:\tlearn: 0.0080845\ttotal: 5.68s\tremaining: 20s\n",
      "221:\tlearn: 0.0080718\ttotal: 5.7s\tremaining: 20s\n",
      "222:\tlearn: 0.0080538\ttotal: 5.72s\tremaining: 19.9s\n",
      "223:\tlearn: 0.0080130\ttotal: 5.75s\tremaining: 19.9s\n",
      "224:\tlearn: 0.0079914\ttotal: 5.78s\tremaining: 19.9s\n",
      "225:\tlearn: 0.0079543\ttotal: 5.8s\tremaining: 19.9s\n",
      "226:\tlearn: 0.0079386\ttotal: 5.83s\tremaining: 19.8s\n",
      "227:\tlearn: 0.0079144\ttotal: 5.85s\tremaining: 19.8s\n",
      "228:\tlearn: 0.0078914\ttotal: 5.88s\tremaining: 19.8s\n",
      "229:\tlearn: 0.0078544\ttotal: 5.9s\tremaining: 19.8s\n",
      "230:\tlearn: 0.0078322\ttotal: 5.93s\tremaining: 19.8s\n",
      "231:\tlearn: 0.0078189\ttotal: 5.96s\tremaining: 19.7s\n",
      "232:\tlearn: 0.0078101\ttotal: 5.98s\tremaining: 19.7s\n",
      "233:\tlearn: 0.0077831\ttotal: 6s\tremaining: 19.7s\n",
      "234:\tlearn: 0.0077553\ttotal: 6.03s\tremaining: 19.6s\n",
      "235:\tlearn: 0.0077363\ttotal: 6.05s\tremaining: 19.6s\n",
      "236:\tlearn: 0.0077247\ttotal: 6.08s\tremaining: 19.6s\n",
      "237:\tlearn: 0.0077114\ttotal: 6.1s\tremaining: 19.5s\n",
      "238:\tlearn: 0.0076933\ttotal: 6.13s\tremaining: 19.5s\n",
      "239:\tlearn: 0.0076747\ttotal: 6.15s\tremaining: 19.5s\n",
      "240:\tlearn: 0.0076278\ttotal: 6.18s\tremaining: 19.5s\n",
      "241:\tlearn: 0.0076193\ttotal: 6.21s\tremaining: 19.4s\n",
      "242:\tlearn: 0.0076098\ttotal: 6.23s\tremaining: 19.4s\n",
      "243:\tlearn: 0.0076002\ttotal: 6.25s\tremaining: 19.4s\n",
      "244:\tlearn: 0.0075955\ttotal: 6.27s\tremaining: 19.3s\n",
      "245:\tlearn: 0.0075883\ttotal: 6.29s\tremaining: 19.3s\n",
      "246:\tlearn: 0.0075817\ttotal: 6.32s\tremaining: 19.3s\n",
      "247:\tlearn: 0.0075785\ttotal: 6.34s\tremaining: 19.2s\n",
      "248:\tlearn: 0.0075725\ttotal: 6.37s\tremaining: 19.2s\n",
      "249:\tlearn: 0.0075683\ttotal: 6.39s\tremaining: 19.2s\n",
      "250:\tlearn: 0.0075387\ttotal: 6.41s\tremaining: 19.1s\n",
      "251:\tlearn: 0.0075311\ttotal: 6.43s\tremaining: 19.1s\n",
      "252:\tlearn: 0.0075231\ttotal: 6.45s\tremaining: 19.1s\n",
      "253:\tlearn: 0.0075121\ttotal: 6.48s\tremaining: 19s\n",
      "254:\tlearn: 0.0075058\ttotal: 6.5s\tremaining: 19s\n",
      "255:\tlearn: 0.0074790\ttotal: 6.53s\tremaining: 19s\n",
      "256:\tlearn: 0.0074704\ttotal: 6.55s\tremaining: 18.9s\n",
      "257:\tlearn: 0.0074491\ttotal: 6.58s\tremaining: 18.9s\n",
      "258:\tlearn: 0.0074232\ttotal: 6.61s\tremaining: 18.9s\n",
      "259:\tlearn: 0.0074080\ttotal: 6.63s\tremaining: 18.9s\n",
      "260:\tlearn: 0.0074019\ttotal: 6.66s\tremaining: 18.9s\n",
      "261:\tlearn: 0.0073777\ttotal: 6.7s\tremaining: 18.9s\n",
      "262:\tlearn: 0.0073528\ttotal: 6.74s\tremaining: 18.9s\n",
      "263:\tlearn: 0.0073371\ttotal: 6.77s\tremaining: 18.9s\n",
      "264:\tlearn: 0.0073186\ttotal: 6.8s\tremaining: 18.9s\n",
      "265:\tlearn: 0.0072919\ttotal: 6.83s\tremaining: 18.8s\n",
      "266:\tlearn: 0.0072772\ttotal: 6.86s\tremaining: 18.8s\n",
      "267:\tlearn: 0.0072516\ttotal: 6.88s\tremaining: 18.8s\n",
      "268:\tlearn: 0.0072458\ttotal: 6.91s\tremaining: 18.8s\n",
      "269:\tlearn: 0.0072307\ttotal: 6.93s\tremaining: 18.7s\n",
      "270:\tlearn: 0.0071848\ttotal: 6.96s\tremaining: 18.7s\n",
      "271:\tlearn: 0.0071641\ttotal: 6.98s\tremaining: 18.7s\n",
      "272:\tlearn: 0.0071549\ttotal: 7s\tremaining: 18.7s\n",
      "273:\tlearn: 0.0071512\ttotal: 7.03s\tremaining: 18.6s\n",
      "274:\tlearn: 0.0071333\ttotal: 7.06s\tremaining: 18.6s\n",
      "275:\tlearn: 0.0071093\ttotal: 7.08s\tremaining: 18.6s\n",
      "276:\tlearn: 0.0070825\ttotal: 7.11s\tremaining: 18.5s\n",
      "277:\tlearn: 0.0070674\ttotal: 7.13s\tremaining: 18.5s\n",
      "278:\tlearn: 0.0070298\ttotal: 7.15s\tremaining: 18.5s\n",
      "279:\tlearn: 0.0069715\ttotal: 7.18s\tremaining: 18.5s\n",
      "280:\tlearn: 0.0069564\ttotal: 7.21s\tremaining: 18.4s\n",
      "281:\tlearn: 0.0069531\ttotal: 7.23s\tremaining: 18.4s\n",
      "282:\tlearn: 0.0069405\ttotal: 7.25s\tremaining: 18.4s\n",
      "283:\tlearn: 0.0069288\ttotal: 7.27s\tremaining: 18.3s\n",
      "284:\tlearn: 0.0069253\ttotal: 7.29s\tremaining: 18.3s\n",
      "285:\tlearn: 0.0069223\ttotal: 7.31s\tremaining: 18.3s\n",
      "286:\tlearn: 0.0068999\ttotal: 7.34s\tremaining: 18.2s\n",
      "287:\tlearn: 0.0068676\ttotal: 7.36s\tremaining: 18.2s\n",
      "288:\tlearn: 0.0068518\ttotal: 7.39s\tremaining: 18.2s\n",
      "289:\tlearn: 0.0068396\ttotal: 7.42s\tremaining: 18.2s\n",
      "290:\tlearn: 0.0068279\ttotal: 7.44s\tremaining: 18.1s\n",
      "291:\tlearn: 0.0067827\ttotal: 7.47s\tremaining: 18.1s\n",
      "292:\tlearn: 0.0067689\ttotal: 7.49s\tremaining: 18.1s\n",
      "293:\tlearn: 0.0067517\ttotal: 7.51s\tremaining: 18s\n",
      "294:\tlearn: 0.0067464\ttotal: 7.54s\tremaining: 18s\n",
      "295:\tlearn: 0.0067233\ttotal: 7.57s\tremaining: 18s\n",
      "296:\tlearn: 0.0067103\ttotal: 7.59s\tremaining: 18s\n",
      "297:\tlearn: 0.0067013\ttotal: 7.62s\tremaining: 18s\n",
      "298:\tlearn: 0.0066872\ttotal: 7.65s\tremaining: 17.9s\n",
      "299:\tlearn: 0.0066845\ttotal: 7.67s\tremaining: 17.9s\n",
      "300:\tlearn: 0.0066827\ttotal: 7.69s\tremaining: 17.9s\n",
      "301:\tlearn: 0.0066728\ttotal: 7.71s\tremaining: 17.8s\n",
      "302:\tlearn: 0.0066467\ttotal: 7.74s\tremaining: 17.8s\n",
      "303:\tlearn: 0.0066394\ttotal: 7.77s\tremaining: 17.8s\n",
      "304:\tlearn: 0.0066255\ttotal: 7.79s\tremaining: 17.8s\n",
      "305:\tlearn: 0.0066172\ttotal: 7.82s\tremaining: 17.7s\n",
      "306:\tlearn: 0.0066129\ttotal: 7.85s\tremaining: 17.7s\n",
      "307:\tlearn: 0.0066104\ttotal: 7.88s\tremaining: 17.7s\n",
      "308:\tlearn: 0.0065985\ttotal: 7.91s\tremaining: 17.7s\n",
      "309:\tlearn: 0.0065875\ttotal: 7.93s\tremaining: 17.7s\n",
      "310:\tlearn: 0.0065789\ttotal: 7.96s\tremaining: 17.6s\n",
      "311:\tlearn: 0.0065762\ttotal: 7.98s\tremaining: 17.6s\n",
      "312:\tlearn: 0.0065715\ttotal: 8.01s\tremaining: 17.6s\n",
      "313:\tlearn: 0.0065695\ttotal: 8.03s\tremaining: 17.5s\n",
      "314:\tlearn: 0.0065657\ttotal: 8.05s\tremaining: 17.5s\n",
      "315:\tlearn: 0.0065485\ttotal: 8.08s\tremaining: 17.5s\n",
      "316:\tlearn: 0.0065396\ttotal: 8.11s\tremaining: 17.5s\n",
      "317:\tlearn: 0.0065283\ttotal: 8.13s\tremaining: 17.4s\n",
      "318:\tlearn: 0.0065129\ttotal: 8.15s\tremaining: 17.4s\n",
      "319:\tlearn: 0.0064871\ttotal: 8.18s\tremaining: 17.4s\n",
      "320:\tlearn: 0.0064825\ttotal: 8.2s\tremaining: 17.3s\n",
      "321:\tlearn: 0.0064757\ttotal: 8.22s\tremaining: 17.3s\n",
      "322:\tlearn: 0.0064740\ttotal: 8.25s\tremaining: 17.3s\n",
      "323:\tlearn: 0.0064622\ttotal: 8.27s\tremaining: 17.3s\n",
      "324:\tlearn: 0.0064379\ttotal: 8.3s\tremaining: 17.2s\n",
      "325:\tlearn: 0.0064062\ttotal: 8.33s\tremaining: 17.2s\n",
      "326:\tlearn: 0.0063858\ttotal: 8.35s\tremaining: 17.2s\n",
      "327:\tlearn: 0.0063602\ttotal: 8.37s\tremaining: 17.2s\n",
      "328:\tlearn: 0.0063547\ttotal: 8.39s\tremaining: 17.1s\n",
      "329:\tlearn: 0.0063517\ttotal: 8.41s\tremaining: 17.1s\n",
      "330:\tlearn: 0.0063432\ttotal: 8.45s\tremaining: 17.1s\n",
      "331:\tlearn: 0.0063381\ttotal: 8.47s\tremaining: 17s\n",
      "332:\tlearn: 0.0063083\ttotal: 8.49s\tremaining: 17s\n",
      "333:\tlearn: 0.0062954\ttotal: 8.52s\tremaining: 17s\n",
      "334:\tlearn: 0.0062809\ttotal: 8.54s\tremaining: 17s\n",
      "335:\tlearn: 0.0062757\ttotal: 8.57s\tremaining: 16.9s\n",
      "336:\tlearn: 0.0062680\ttotal: 8.59s\tremaining: 16.9s\n",
      "337:\tlearn: 0.0062433\ttotal: 8.62s\tremaining: 16.9s\n",
      "338:\tlearn: 0.0062212\ttotal: 8.65s\tremaining: 16.9s\n",
      "339:\tlearn: 0.0061992\ttotal: 8.67s\tremaining: 16.8s\n",
      "340:\tlearn: 0.0061781\ttotal: 8.69s\tremaining: 16.8s\n",
      "341:\tlearn: 0.0061677\ttotal: 8.71s\tremaining: 16.8s\n",
      "342:\tlearn: 0.0061509\ttotal: 8.74s\tremaining: 16.7s\n",
      "343:\tlearn: 0.0061431\ttotal: 8.76s\tremaining: 16.7s\n",
      "344:\tlearn: 0.0061292\ttotal: 8.79s\tremaining: 16.7s\n",
      "345:\tlearn: 0.0061199\ttotal: 8.81s\tremaining: 16.7s\n",
      "346:\tlearn: 0.0061094\ttotal: 8.84s\tremaining: 16.6s\n",
      "347:\tlearn: 0.0060877\ttotal: 8.86s\tremaining: 16.6s\n",
      "348:\tlearn: 0.0060668\ttotal: 8.9s\tremaining: 16.6s\n",
      "349:\tlearn: 0.0060456\ttotal: 8.93s\tremaining: 16.6s\n",
      "350:\tlearn: 0.0060292\ttotal: 8.97s\tremaining: 16.6s\n",
      "351:\tlearn: 0.0060216\ttotal: 9s\tremaining: 16.6s\n",
      "352:\tlearn: 0.0060107\ttotal: 9.03s\tremaining: 16.5s\n",
      "353:\tlearn: 0.0060033\ttotal: 9.06s\tremaining: 16.5s\n",
      "354:\tlearn: 0.0059950\ttotal: 9.08s\tremaining: 16.5s\n",
      "355:\tlearn: 0.0059433\ttotal: 9.11s\tremaining: 16.5s\n",
      "356:\tlearn: 0.0059198\ttotal: 9.13s\tremaining: 16.4s\n",
      "357:\tlearn: 0.0058938\ttotal: 9.16s\tremaining: 16.4s\n",
      "358:\tlearn: 0.0058643\ttotal: 9.18s\tremaining: 16.4s\n",
      "359:\tlearn: 0.0058510\ttotal: 9.21s\tremaining: 16.4s\n",
      "360:\tlearn: 0.0058495\ttotal: 9.23s\tremaining: 16.3s\n",
      "361:\tlearn: 0.0058442\ttotal: 9.26s\tremaining: 16.3s\n",
      "362:\tlearn: 0.0058428\ttotal: 9.28s\tremaining: 16.3s\n",
      "363:\tlearn: 0.0058364\ttotal: 9.3s\tremaining: 16.3s\n",
      "364:\tlearn: 0.0058301\ttotal: 9.32s\tremaining: 16.2s\n",
      "365:\tlearn: 0.0058116\ttotal: 9.35s\tremaining: 16.2s\n",
      "366:\tlearn: 0.0058085\ttotal: 9.37s\tremaining: 16.2s\n",
      "367:\tlearn: 0.0058024\ttotal: 9.39s\tremaining: 16.1s\n",
      "368:\tlearn: 0.0058012\ttotal: 9.42s\tremaining: 16.1s\n",
      "369:\tlearn: 0.0057932\ttotal: 9.44s\tremaining: 16.1s\n",
      "370:\tlearn: 0.0057918\ttotal: 9.46s\tremaining: 16s\n",
      "371:\tlearn: 0.0057874\ttotal: 9.49s\tremaining: 16s\n",
      "372:\tlearn: 0.0057784\ttotal: 9.51s\tremaining: 16s\n",
      "373:\tlearn: 0.0057699\ttotal: 9.53s\tremaining: 16s\n",
      "374:\tlearn: 0.0057688\ttotal: 9.55s\tremaining: 15.9s\n",
      "375:\tlearn: 0.0057593\ttotal: 9.58s\tremaining: 15.9s\n",
      "376:\tlearn: 0.0057539\ttotal: 9.6s\tremaining: 15.9s\n",
      "377:\tlearn: 0.0057384\ttotal: 9.63s\tremaining: 15.8s\n",
      "378:\tlearn: 0.0057310\ttotal: 9.65s\tremaining: 15.8s\n",
      "379:\tlearn: 0.0057248\ttotal: 9.67s\tremaining: 15.8s\n",
      "380:\tlearn: 0.0057114\ttotal: 9.69s\tremaining: 15.7s\n",
      "381:\tlearn: 0.0057100\ttotal: 9.71s\tremaining: 15.7s\n",
      "382:\tlearn: 0.0057069\ttotal: 9.74s\tremaining: 15.7s\n",
      "383:\tlearn: 0.0057018\ttotal: 9.77s\tremaining: 15.7s\n",
      "384:\tlearn: 0.0057005\ttotal: 9.79s\tremaining: 15.6s\n",
      "385:\tlearn: 0.0056687\ttotal: 9.81s\tremaining: 15.6s\n",
      "386:\tlearn: 0.0056546\ttotal: 9.84s\tremaining: 15.6s\n",
      "387:\tlearn: 0.0056416\ttotal: 9.86s\tremaining: 15.5s\n",
      "388:\tlearn: 0.0056208\ttotal: 9.88s\tremaining: 15.5s\n",
      "389:\tlearn: 0.0056089\ttotal: 9.91s\tremaining: 15.5s\n",
      "390:\tlearn: 0.0055933\ttotal: 9.93s\tremaining: 15.5s\n",
      "391:\tlearn: 0.0055789\ttotal: 9.96s\tremaining: 15.4s\n",
      "392:\tlearn: 0.0055629\ttotal: 9.98s\tremaining: 15.4s\n",
      "393:\tlearn: 0.0055490\ttotal: 10s\tremaining: 15.4s\n",
      "394:\tlearn: 0.0055375\ttotal: 10s\tremaining: 15.4s\n",
      "395:\tlearn: 0.0055194\ttotal: 10.1s\tremaining: 15.4s\n",
      "396:\tlearn: 0.0054926\ttotal: 10.1s\tremaining: 15.3s\n",
      "397:\tlearn: 0.0054798\ttotal: 10.1s\tremaining: 15.3s\n",
      "398:\tlearn: 0.0054759\ttotal: 10.2s\tremaining: 15.3s\n",
      "399:\tlearn: 0.0054517\ttotal: 10.2s\tremaining: 15.3s\n",
      "400:\tlearn: 0.0054260\ttotal: 10.2s\tremaining: 15.2s\n",
      "401:\tlearn: 0.0054122\ttotal: 10.2s\tremaining: 15.2s\n",
      "402:\tlearn: 0.0053988\ttotal: 10.3s\tremaining: 15.2s\n",
      "403:\tlearn: 0.0053784\ttotal: 10.3s\tremaining: 15.2s\n",
      "404:\tlearn: 0.0053602\ttotal: 10.3s\tremaining: 15.2s\n",
      "405:\tlearn: 0.0053473\ttotal: 10.3s\tremaining: 15.1s\n",
      "406:\tlearn: 0.0053350\ttotal: 10.4s\tremaining: 15.1s\n",
      "407:\tlearn: 0.0053265\ttotal: 10.4s\tremaining: 15.1s\n",
      "408:\tlearn: 0.0053209\ttotal: 10.4s\tremaining: 15s\n",
      "409:\tlearn: 0.0053121\ttotal: 10.4s\tremaining: 15s\n",
      "410:\tlearn: 0.0053012\ttotal: 10.5s\tremaining: 15s\n",
      "411:\tlearn: 0.0052784\ttotal: 10.5s\tremaining: 15s\n",
      "412:\tlearn: 0.0052773\ttotal: 10.5s\tremaining: 14.9s\n",
      "413:\tlearn: 0.0052583\ttotal: 10.5s\tremaining: 14.9s\n",
      "414:\tlearn: 0.0052377\ttotal: 10.6s\tremaining: 14.9s\n",
      "415:\tlearn: 0.0052237\ttotal: 10.6s\tremaining: 14.9s\n",
      "416:\tlearn: 0.0052032\ttotal: 10.6s\tremaining: 14.8s\n",
      "417:\tlearn: 0.0051938\ttotal: 10.6s\tremaining: 14.8s\n",
      "418:\tlearn: 0.0051650\ttotal: 10.7s\tremaining: 14.8s\n",
      "419:\tlearn: 0.0051512\ttotal: 10.7s\tremaining: 14.8s\n",
      "420:\tlearn: 0.0051436\ttotal: 10.7s\tremaining: 14.8s\n",
      "421:\tlearn: 0.0051426\ttotal: 10.8s\tremaining: 14.7s\n",
      "422:\tlearn: 0.0051355\ttotal: 10.8s\tremaining: 14.7s\n",
      "423:\tlearn: 0.0051289\ttotal: 10.8s\tremaining: 14.7s\n",
      "424:\tlearn: 0.0051280\ttotal: 10.8s\tremaining: 14.6s\n",
      "425:\tlearn: 0.0051061\ttotal: 10.8s\tremaining: 14.6s\n",
      "426:\tlearn: 0.0050948\ttotal: 10.9s\tremaining: 14.6s\n",
      "427:\tlearn: 0.0050906\ttotal: 10.9s\tremaining: 14.6s\n",
      "428:\tlearn: 0.0050819\ttotal: 10.9s\tremaining: 14.5s\n",
      "429:\tlearn: 0.0050772\ttotal: 10.9s\tremaining: 14.5s\n",
      "430:\tlearn: 0.0050727\ttotal: 11s\tremaining: 14.5s\n",
      "431:\tlearn: 0.0050672\ttotal: 11s\tremaining: 14.4s\n",
      "432:\tlearn: 0.0050612\ttotal: 11s\tremaining: 14.4s\n",
      "433:\tlearn: 0.0050581\ttotal: 11s\tremaining: 14.4s\n",
      "434:\tlearn: 0.0050554\ttotal: 11s\tremaining: 14.3s\n",
      "435:\tlearn: 0.0050509\ttotal: 11.1s\tremaining: 14.3s\n",
      "436:\tlearn: 0.0050191\ttotal: 11.1s\tremaining: 14.3s\n",
      "437:\tlearn: 0.0050162\ttotal: 11.1s\tremaining: 14.3s\n",
      "438:\tlearn: 0.0050154\ttotal: 11.1s\tremaining: 14.2s\n",
      "439:\tlearn: 0.0050110\ttotal: 11.2s\tremaining: 14.2s\n",
      "440:\tlearn: 0.0050044\ttotal: 11.2s\tremaining: 14.2s\n",
      "441:\tlearn: 0.0050010\ttotal: 11.2s\tremaining: 14.2s\n",
      "442:\tlearn: 0.0049937\ttotal: 11.2s\tremaining: 14.1s\n",
      "443:\tlearn: 0.0049910\ttotal: 11.3s\tremaining: 14.1s\n",
      "444:\tlearn: 0.0049852\ttotal: 11.3s\tremaining: 14.1s\n",
      "445:\tlearn: 0.0049788\ttotal: 11.3s\tremaining: 14.1s\n",
      "446:\tlearn: 0.0049755\ttotal: 11.3s\tremaining: 14s\n",
      "447:\tlearn: 0.0049539\ttotal: 11.4s\tremaining: 14s\n",
      "448:\tlearn: 0.0049342\ttotal: 11.4s\tremaining: 14s\n",
      "449:\tlearn: 0.0049282\ttotal: 11.4s\tremaining: 13.9s\n",
      "450:\tlearn: 0.0049268\ttotal: 11.4s\tremaining: 13.9s\n",
      "451:\tlearn: 0.0049218\ttotal: 11.4s\tremaining: 13.9s\n",
      "452:\tlearn: 0.0049209\ttotal: 11.5s\tremaining: 13.8s\n",
      "453:\tlearn: 0.0049187\ttotal: 11.5s\tremaining: 13.8s\n",
      "454:\tlearn: 0.0049178\ttotal: 11.5s\tremaining: 13.8s\n",
      "455:\tlearn: 0.0049151\ttotal: 11.5s\tremaining: 13.8s\n",
      "456:\tlearn: 0.0049096\ttotal: 11.5s\tremaining: 13.7s\n",
      "457:\tlearn: 0.0049024\ttotal: 11.6s\tremaining: 13.7s\n",
      "458:\tlearn: 0.0048904\ttotal: 11.6s\tremaining: 13.7s\n",
      "459:\tlearn: 0.0048882\ttotal: 11.6s\tremaining: 13.6s\n",
      "460:\tlearn: 0.0048788\ttotal: 11.6s\tremaining: 13.6s\n",
      "461:\tlearn: 0.0048727\ttotal: 11.7s\tremaining: 13.6s\n",
      "462:\tlearn: 0.0048684\ttotal: 11.7s\tremaining: 13.5s\n",
      "463:\tlearn: 0.0048620\ttotal: 11.7s\tremaining: 13.5s\n",
      "464:\tlearn: 0.0048575\ttotal: 11.7s\tremaining: 13.5s\n",
      "465:\tlearn: 0.0048225\ttotal: 11.7s\tremaining: 13.5s\n",
      "466:\tlearn: 0.0048014\ttotal: 11.8s\tremaining: 13.4s\n",
      "467:\tlearn: 0.0047950\ttotal: 11.8s\tremaining: 13.4s\n",
      "468:\tlearn: 0.0047782\ttotal: 11.8s\tremaining: 13.4s\n",
      "469:\tlearn: 0.0047620\ttotal: 11.8s\tremaining: 13.3s\n",
      "470:\tlearn: 0.0047565\ttotal: 11.9s\tremaining: 13.3s\n",
      "471:\tlearn: 0.0047445\ttotal: 11.9s\tremaining: 13.3s\n",
      "472:\tlearn: 0.0047408\ttotal: 11.9s\tremaining: 13.3s\n",
      "473:\tlearn: 0.0047371\ttotal: 11.9s\tremaining: 13.2s\n",
      "474:\tlearn: 0.0047351\ttotal: 11.9s\tremaining: 13.2s\n",
      "475:\tlearn: 0.0047233\ttotal: 12s\tremaining: 13.2s\n",
      "476:\tlearn: 0.0047214\ttotal: 12s\tremaining: 13.1s\n",
      "477:\tlearn: 0.0046998\ttotal: 12s\tremaining: 13.1s\n",
      "478:\tlearn: 0.0046807\ttotal: 12s\tremaining: 13.1s\n",
      "479:\tlearn: 0.0046658\ttotal: 12.1s\tremaining: 13.1s\n",
      "480:\tlearn: 0.0046651\ttotal: 12.1s\tremaining: 13s\n",
      "481:\tlearn: 0.0046565\ttotal: 12.1s\tremaining: 13s\n",
      "482:\tlearn: 0.0046558\ttotal: 12.1s\tremaining: 13s\n",
      "483:\tlearn: 0.0046508\ttotal: 12.1s\tremaining: 12.9s\n",
      "484:\tlearn: 0.0046426\ttotal: 12.2s\tremaining: 12.9s\n",
      "485:\tlearn: 0.0046292\ttotal: 12.2s\tremaining: 12.9s\n",
      "486:\tlearn: 0.0046209\ttotal: 12.2s\tremaining: 12.9s\n",
      "487:\tlearn: 0.0046060\ttotal: 12.2s\tremaining: 12.8s\n",
      "488:\tlearn: 0.0045904\ttotal: 12.3s\tremaining: 12.8s\n",
      "489:\tlearn: 0.0045763\ttotal: 12.3s\tremaining: 12.8s\n",
      "490:\tlearn: 0.0045628\ttotal: 12.3s\tremaining: 12.8s\n",
      "491:\tlearn: 0.0045552\ttotal: 12.3s\tremaining: 12.8s\n",
      "492:\tlearn: 0.0045495\ttotal: 12.4s\tremaining: 12.7s\n",
      "493:\tlearn: 0.0045400\ttotal: 12.4s\tremaining: 12.7s\n",
      "494:\tlearn: 0.0045383\ttotal: 12.4s\tremaining: 12.7s\n",
      "495:\tlearn: 0.0045377\ttotal: 12.4s\tremaining: 12.6s\n",
      "496:\tlearn: 0.0045091\ttotal: 12.5s\tremaining: 12.6s\n",
      "497:\tlearn: 0.0045020\ttotal: 12.5s\tremaining: 12.6s\n",
      "498:\tlearn: 0.0044952\ttotal: 12.5s\tremaining: 12.6s\n",
      "499:\tlearn: 0.0044909\ttotal: 12.5s\tremaining: 12.5s\n",
      "500:\tlearn: 0.0044849\ttotal: 12.6s\tremaining: 12.5s\n",
      "501:\tlearn: 0.0044769\ttotal: 12.6s\tremaining: 12.5s\n",
      "502:\tlearn: 0.0044643\ttotal: 12.6s\tremaining: 12.4s\n",
      "503:\tlearn: 0.0044619\ttotal: 12.6s\tremaining: 12.4s\n",
      "504:\tlearn: 0.0044589\ttotal: 12.6s\tremaining: 12.4s\n",
      "505:\tlearn: 0.0044576\ttotal: 12.7s\tremaining: 12.4s\n",
      "506:\tlearn: 0.0044559\ttotal: 12.7s\tremaining: 12.3s\n",
      "507:\tlearn: 0.0044504\ttotal: 12.7s\tremaining: 12.3s\n",
      "508:\tlearn: 0.0044459\ttotal: 12.7s\tremaining: 12.3s\n",
      "509:\tlearn: 0.0044324\ttotal: 12.7s\tremaining: 12.2s\n",
      "510:\tlearn: 0.0044258\ttotal: 12.8s\tremaining: 12.2s\n",
      "511:\tlearn: 0.0044124\ttotal: 12.8s\tremaining: 12.2s\n",
      "512:\tlearn: 0.0044050\ttotal: 12.8s\tremaining: 12.2s\n",
      "513:\tlearn: 0.0043904\ttotal: 12.8s\tremaining: 12.1s\n",
      "514:\tlearn: 0.0043819\ttotal: 12.9s\tremaining: 12.1s\n",
      "515:\tlearn: 0.0043793\ttotal: 12.9s\tremaining: 12.1s\n",
      "516:\tlearn: 0.0043670\ttotal: 12.9s\tremaining: 12s\n",
      "517:\tlearn: 0.0043605\ttotal: 12.9s\tremaining: 12s\n",
      "518:\tlearn: 0.0043348\ttotal: 12.9s\tremaining: 12s\n",
      "519:\tlearn: 0.0043257\ttotal: 13s\tremaining: 12s\n",
      "520:\tlearn: 0.0043149\ttotal: 13s\tremaining: 11.9s\n",
      "521:\tlearn: 0.0043054\ttotal: 13s\tremaining: 11.9s\n",
      "522:\tlearn: 0.0042921\ttotal: 13s\tremaining: 11.9s\n",
      "523:\tlearn: 0.0042859\ttotal: 13.1s\tremaining: 11.9s\n",
      "524:\tlearn: 0.0042813\ttotal: 13.1s\tremaining: 11.8s\n",
      "525:\tlearn: 0.0042696\ttotal: 13.1s\tremaining: 11.8s\n",
      "526:\tlearn: 0.0042606\ttotal: 13.1s\tremaining: 11.8s\n",
      "527:\tlearn: 0.0042363\ttotal: 13.2s\tremaining: 11.8s\n",
      "528:\tlearn: 0.0042212\ttotal: 13.2s\tremaining: 11.7s\n",
      "529:\tlearn: 0.0042194\ttotal: 13.2s\tremaining: 11.7s\n",
      "530:\tlearn: 0.0042074\ttotal: 13.2s\tremaining: 11.7s\n",
      "531:\tlearn: 0.0041992\ttotal: 13.2s\tremaining: 11.6s\n",
      "532:\tlearn: 0.0041949\ttotal: 13.3s\tremaining: 11.6s\n",
      "533:\tlearn: 0.0041885\ttotal: 13.3s\tremaining: 11.6s\n",
      "534:\tlearn: 0.0041621\ttotal: 13.3s\tremaining: 11.6s\n",
      "535:\tlearn: 0.0041568\ttotal: 13.3s\tremaining: 11.5s\n",
      "536:\tlearn: 0.0041525\ttotal: 13.3s\tremaining: 11.5s\n",
      "537:\tlearn: 0.0041430\ttotal: 13.4s\tremaining: 11.5s\n",
      "538:\tlearn: 0.0041244\ttotal: 13.4s\tremaining: 11.5s\n",
      "539:\tlearn: 0.0041039\ttotal: 13.4s\tremaining: 11.4s\n",
      "540:\tlearn: 0.0040831\ttotal: 13.5s\tremaining: 11.4s\n",
      "541:\tlearn: 0.0040644\ttotal: 13.5s\tremaining: 11.4s\n",
      "542:\tlearn: 0.0040593\ttotal: 13.5s\tremaining: 11.4s\n",
      "543:\tlearn: 0.0040509\ttotal: 13.5s\tremaining: 11.3s\n",
      "544:\tlearn: 0.0040462\ttotal: 13.6s\tremaining: 11.3s\n",
      "545:\tlearn: 0.0040144\ttotal: 13.6s\tremaining: 11.3s\n",
      "546:\tlearn: 0.0040109\ttotal: 13.6s\tremaining: 11.3s\n",
      "547:\tlearn: 0.0040103\ttotal: 13.6s\tremaining: 11.2s\n",
      "548:\tlearn: 0.0040005\ttotal: 13.6s\tremaining: 11.2s\n",
      "549:\tlearn: 0.0039941\ttotal: 13.7s\tremaining: 11.2s\n",
      "550:\tlearn: 0.0039935\ttotal: 13.7s\tremaining: 11.2s\n",
      "551:\tlearn: 0.0039719\ttotal: 13.7s\tremaining: 11.1s\n",
      "552:\tlearn: 0.0039632\ttotal: 13.7s\tremaining: 11.1s\n",
      "553:\tlearn: 0.0039576\ttotal: 13.8s\tremaining: 11.1s\n",
      "554:\tlearn: 0.0039544\ttotal: 13.8s\tremaining: 11s\n",
      "555:\tlearn: 0.0039379\ttotal: 13.8s\tremaining: 11s\n",
      "556:\tlearn: 0.0039317\ttotal: 13.8s\tremaining: 11s\n",
      "557:\tlearn: 0.0039271\ttotal: 13.8s\tremaining: 11s\n",
      "558:\tlearn: 0.0039262\ttotal: 13.9s\tremaining: 10.9s\n",
      "559:\tlearn: 0.0039231\ttotal: 13.9s\tremaining: 10.9s\n",
      "560:\tlearn: 0.0039154\ttotal: 13.9s\tremaining: 10.9s\n",
      "561:\tlearn: 0.0039053\ttotal: 13.9s\tremaining: 10.9s\n",
      "562:\tlearn: 0.0039027\ttotal: 14s\tremaining: 10.8s\n",
      "563:\tlearn: 0.0039022\ttotal: 14s\tremaining: 10.8s\n",
      "564:\tlearn: 0.0039003\ttotal: 14s\tremaining: 10.8s\n",
      "565:\tlearn: 0.0038959\ttotal: 14s\tremaining: 10.7s\n",
      "566:\tlearn: 0.0038786\ttotal: 14s\tremaining: 10.7s\n",
      "567:\tlearn: 0.0038762\ttotal: 14.1s\tremaining: 10.7s\n",
      "568:\tlearn: 0.0038755\ttotal: 14.1s\tremaining: 10.7s\n",
      "569:\tlearn: 0.0038750\ttotal: 14.1s\tremaining: 10.6s\n",
      "570:\tlearn: 0.0038744\ttotal: 14.1s\tremaining: 10.6s\n",
      "571:\tlearn: 0.0038731\ttotal: 14.1s\tremaining: 10.6s\n",
      "572:\tlearn: 0.0038725\ttotal: 14.2s\tremaining: 10.6s\n",
      "573:\tlearn: 0.0038638\ttotal: 14.2s\tremaining: 10.5s\n",
      "574:\tlearn: 0.0038632\ttotal: 14.2s\tremaining: 10.5s\n",
      "575:\tlearn: 0.0038543\ttotal: 14.2s\tremaining: 10.5s\n",
      "576:\tlearn: 0.0038493\ttotal: 14.3s\tremaining: 10.5s\n",
      "577:\tlearn: 0.0038426\ttotal: 14.3s\tremaining: 10.4s\n",
      "578:\tlearn: 0.0038419\ttotal: 14.3s\tremaining: 10.4s\n",
      "579:\tlearn: 0.0038343\ttotal: 14.3s\tremaining: 10.4s\n",
      "580:\tlearn: 0.0038301\ttotal: 14.3s\tremaining: 10.3s\n",
      "581:\tlearn: 0.0038201\ttotal: 14.4s\tremaining: 10.3s\n",
      "582:\tlearn: 0.0038150\ttotal: 14.4s\tremaining: 10.3s\n",
      "583:\tlearn: 0.0038102\ttotal: 14.4s\tremaining: 10.3s\n",
      "584:\tlearn: 0.0038098\ttotal: 14.4s\tremaining: 10.2s\n",
      "585:\tlearn: 0.0038040\ttotal: 14.5s\tremaining: 10.2s\n",
      "586:\tlearn: 0.0037890\ttotal: 14.5s\tremaining: 10.2s\n",
      "587:\tlearn: 0.0037863\ttotal: 14.5s\tremaining: 10.2s\n",
      "588:\tlearn: 0.0037801\ttotal: 14.5s\tremaining: 10.1s\n",
      "589:\tlearn: 0.0037710\ttotal: 14.6s\tremaining: 10.1s\n",
      "590:\tlearn: 0.0037657\ttotal: 14.6s\tremaining: 10.1s\n",
      "591:\tlearn: 0.0037653\ttotal: 14.6s\tremaining: 10.1s\n",
      "592:\tlearn: 0.0037584\ttotal: 14.6s\tremaining: 10s\n",
      "593:\tlearn: 0.0037528\ttotal: 14.7s\tremaining: 10s\n",
      "594:\tlearn: 0.0037448\ttotal: 14.7s\tremaining: 10s\n",
      "595:\tlearn: 0.0037360\ttotal: 14.7s\tremaining: 9.97s\n",
      "596:\tlearn: 0.0037314\ttotal: 14.7s\tremaining: 9.95s\n",
      "597:\tlearn: 0.0037219\ttotal: 14.8s\tremaining: 9.92s\n",
      "598:\tlearn: 0.0037189\ttotal: 14.8s\tremaining: 9.9s\n",
      "599:\tlearn: 0.0037148\ttotal: 14.8s\tremaining: 9.87s\n",
      "600:\tlearn: 0.0037112\ttotal: 14.8s\tremaining: 9.84s\n",
      "601:\tlearn: 0.0036922\ttotal: 14.8s\tremaining: 9.81s\n",
      "602:\tlearn: 0.0036898\ttotal: 14.9s\tremaining: 9.78s\n",
      "603:\tlearn: 0.0036854\ttotal: 14.9s\tremaining: 9.76s\n",
      "604:\tlearn: 0.0036827\ttotal: 14.9s\tremaining: 9.73s\n",
      "605:\tlearn: 0.0036768\ttotal: 14.9s\tremaining: 9.71s\n",
      "606:\tlearn: 0.0036764\ttotal: 15s\tremaining: 9.68s\n",
      "607:\tlearn: 0.0036706\ttotal: 15s\tremaining: 9.65s\n",
      "608:\tlearn: 0.0036631\ttotal: 15s\tremaining: 9.63s\n",
      "609:\tlearn: 0.0036620\ttotal: 15s\tremaining: 9.6s\n",
      "610:\tlearn: 0.0036559\ttotal: 15s\tremaining: 9.57s\n",
      "611:\tlearn: 0.0036485\ttotal: 15.1s\tremaining: 9.54s\n",
      "612:\tlearn: 0.0036445\ttotal: 15.1s\tremaining: 9.52s\n",
      "613:\tlearn: 0.0036384\ttotal: 15.1s\tremaining: 9.49s\n",
      "614:\tlearn: 0.0036320\ttotal: 15.1s\tremaining: 9.47s\n",
      "615:\tlearn: 0.0036226\ttotal: 15.1s\tremaining: 9.44s\n",
      "616:\tlearn: 0.0036161\ttotal: 15.2s\tremaining: 9.41s\n",
      "617:\tlearn: 0.0036112\ttotal: 15.2s\tremaining: 9.39s\n",
      "618:\tlearn: 0.0035981\ttotal: 15.2s\tremaining: 9.37s\n",
      "619:\tlearn: 0.0035934\ttotal: 15.2s\tremaining: 9.34s\n",
      "620:\tlearn: 0.0035810\ttotal: 15.3s\tremaining: 9.32s\n",
      "621:\tlearn: 0.0035771\ttotal: 15.3s\tremaining: 9.29s\n",
      "622:\tlearn: 0.0035718\ttotal: 15.3s\tremaining: 9.27s\n",
      "623:\tlearn: 0.0035638\ttotal: 15.3s\tremaining: 9.24s\n",
      "624:\tlearn: 0.0035613\ttotal: 15.4s\tremaining: 9.21s\n",
      "625:\tlearn: 0.0035554\ttotal: 15.4s\tremaining: 9.19s\n",
      "626:\tlearn: 0.0035488\ttotal: 15.4s\tremaining: 9.16s\n",
      "627:\tlearn: 0.0035441\ttotal: 15.4s\tremaining: 9.13s\n",
      "628:\tlearn: 0.0035425\ttotal: 15.4s\tremaining: 9.11s\n",
      "629:\tlearn: 0.0035260\ttotal: 15.5s\tremaining: 9.08s\n",
      "630:\tlearn: 0.0035230\ttotal: 15.5s\tremaining: 9.06s\n",
      "631:\tlearn: 0.0035218\ttotal: 15.5s\tremaining: 9.03s\n",
      "632:\tlearn: 0.0035139\ttotal: 15.5s\tremaining: 9s\n",
      "633:\tlearn: 0.0035124\ttotal: 15.6s\tremaining: 8.98s\n",
      "634:\tlearn: 0.0035065\ttotal: 15.6s\tremaining: 8.95s\n",
      "635:\tlearn: 0.0035061\ttotal: 15.6s\tremaining: 8.93s\n",
      "636:\tlearn: 0.0035027\ttotal: 15.6s\tremaining: 8.9s\n",
      "637:\tlearn: 0.0035024\ttotal: 15.6s\tremaining: 8.88s\n",
      "638:\tlearn: 0.0034985\ttotal: 15.7s\tremaining: 8.86s\n",
      "639:\tlearn: 0.0034904\ttotal: 15.7s\tremaining: 8.84s\n",
      "640:\tlearn: 0.0034877\ttotal: 15.7s\tremaining: 8.82s\n",
      "641:\tlearn: 0.0034819\ttotal: 15.8s\tremaining: 8.79s\n",
      "642:\tlearn: 0.0034795\ttotal: 15.8s\tremaining: 8.77s\n",
      "643:\tlearn: 0.0034724\ttotal: 15.8s\tremaining: 8.74s\n",
      "644:\tlearn: 0.0034701\ttotal: 15.8s\tremaining: 8.72s\n",
      "645:\tlearn: 0.0034575\ttotal: 15.9s\tremaining: 8.69s\n",
      "646:\tlearn: 0.0034509\ttotal: 15.9s\tremaining: 8.66s\n",
      "647:\tlearn: 0.0034473\ttotal: 15.9s\tremaining: 8.64s\n",
      "648:\tlearn: 0.0034419\ttotal: 15.9s\tremaining: 8.61s\n",
      "649:\tlearn: 0.0034364\ttotal: 15.9s\tremaining: 8.59s\n",
      "650:\tlearn: 0.0034297\ttotal: 16s\tremaining: 8.56s\n",
      "651:\tlearn: 0.0034274\ttotal: 16s\tremaining: 8.54s\n",
      "652:\tlearn: 0.0034223\ttotal: 16s\tremaining: 8.51s\n",
      "653:\tlearn: 0.0034205\ttotal: 16s\tremaining: 8.49s\n",
      "654:\tlearn: 0.0034188\ttotal: 16.1s\tremaining: 8.46s\n",
      "655:\tlearn: 0.0034125\ttotal: 16.1s\tremaining: 8.43s\n",
      "656:\tlearn: 0.0034084\ttotal: 16.1s\tremaining: 8.41s\n",
      "657:\tlearn: 0.0034007\ttotal: 16.1s\tremaining: 8.38s\n",
      "658:\tlearn: 0.0033995\ttotal: 16.1s\tremaining: 8.36s\n",
      "659:\tlearn: 0.0033946\ttotal: 16.2s\tremaining: 8.33s\n",
      "660:\tlearn: 0.0033897\ttotal: 16.2s\tremaining: 8.3s\n",
      "661:\tlearn: 0.0033893\ttotal: 16.2s\tremaining: 8.28s\n",
      "662:\tlearn: 0.0033840\ttotal: 16.2s\tremaining: 8.25s\n",
      "663:\tlearn: 0.0033771\ttotal: 16.3s\tremaining: 8.23s\n",
      "664:\tlearn: 0.0033744\ttotal: 16.3s\tremaining: 8.2s\n",
      "665:\tlearn: 0.0033691\ttotal: 16.3s\tremaining: 8.17s\n",
      "666:\tlearn: 0.0033648\ttotal: 16.3s\tremaining: 8.15s\n",
      "667:\tlearn: 0.0033618\ttotal: 16.3s\tremaining: 8.12s\n",
      "668:\tlearn: 0.0033607\ttotal: 16.4s\tremaining: 8.09s\n",
      "669:\tlearn: 0.0033590\ttotal: 16.4s\tremaining: 8.07s\n",
      "670:\tlearn: 0.0033510\ttotal: 16.4s\tremaining: 8.04s\n",
      "671:\tlearn: 0.0033430\ttotal: 16.4s\tremaining: 8.02s\n",
      "672:\tlearn: 0.0033379\ttotal: 16.4s\tremaining: 7.99s\n",
      "673:\tlearn: 0.0033310\ttotal: 16.5s\tremaining: 7.96s\n",
      "674:\tlearn: 0.0033198\ttotal: 16.5s\tremaining: 7.94s\n",
      "675:\tlearn: 0.0033129\ttotal: 16.5s\tremaining: 7.91s\n",
      "676:\tlearn: 0.0033115\ttotal: 16.5s\tremaining: 7.89s\n",
      "677:\tlearn: 0.0033104\ttotal: 16.6s\tremaining: 7.86s\n",
      "678:\tlearn: 0.0033046\ttotal: 16.6s\tremaining: 7.84s\n",
      "679:\tlearn: 0.0032920\ttotal: 16.6s\tremaining: 7.81s\n",
      "680:\tlearn: 0.0032782\ttotal: 16.6s\tremaining: 7.79s\n",
      "681:\tlearn: 0.0032740\ttotal: 16.6s\tremaining: 7.76s\n",
      "682:\tlearn: 0.0032683\ttotal: 16.7s\tremaining: 7.73s\n",
      "683:\tlearn: 0.0032622\ttotal: 16.7s\tremaining: 7.71s\n",
      "684:\tlearn: 0.0032570\ttotal: 16.7s\tremaining: 7.68s\n",
      "685:\tlearn: 0.0032558\ttotal: 16.7s\tremaining: 7.66s\n",
      "686:\tlearn: 0.0032538\ttotal: 16.8s\tremaining: 7.64s\n",
      "687:\tlearn: 0.0032511\ttotal: 16.8s\tremaining: 7.61s\n",
      "688:\tlearn: 0.0032456\ttotal: 16.8s\tremaining: 7.59s\n",
      "689:\tlearn: 0.0032391\ttotal: 16.8s\tremaining: 7.57s\n",
      "690:\tlearn: 0.0032320\ttotal: 16.9s\tremaining: 7.54s\n",
      "691:\tlearn: 0.0032277\ttotal: 16.9s\tremaining: 7.52s\n",
      "692:\tlearn: 0.0032253\ttotal: 16.9s\tremaining: 7.49s\n",
      "693:\tlearn: 0.0032126\ttotal: 16.9s\tremaining: 7.47s\n",
      "694:\tlearn: 0.0032078\ttotal: 17s\tremaining: 7.44s\n",
      "695:\tlearn: 0.0032075\ttotal: 17s\tremaining: 7.42s\n",
      "696:\tlearn: 0.0031984\ttotal: 17s\tremaining: 7.39s\n",
      "697:\tlearn: 0.0031941\ttotal: 17s\tremaining: 7.37s\n",
      "698:\tlearn: 0.0031936\ttotal: 17s\tremaining: 7.34s\n",
      "699:\tlearn: 0.0031892\ttotal: 17.1s\tremaining: 7.32s\n",
      "700:\tlearn: 0.0031833\ttotal: 17.1s\tremaining: 7.29s\n",
      "701:\tlearn: 0.0031792\ttotal: 17.1s\tremaining: 7.27s\n",
      "702:\tlearn: 0.0031768\ttotal: 17.1s\tremaining: 7.24s\n",
      "703:\tlearn: 0.0031725\ttotal: 17.2s\tremaining: 7.22s\n",
      "704:\tlearn: 0.0031642\ttotal: 17.2s\tremaining: 7.2s\n",
      "705:\tlearn: 0.0031614\ttotal: 17.2s\tremaining: 7.17s\n",
      "706:\tlearn: 0.0031576\ttotal: 17.3s\tremaining: 7.15s\n",
      "707:\tlearn: 0.0031538\ttotal: 17.3s\tremaining: 7.13s\n",
      "708:\tlearn: 0.0031528\ttotal: 17.3s\tremaining: 7.11s\n",
      "709:\tlearn: 0.0031511\ttotal: 17.3s\tremaining: 7.08s\n",
      "710:\tlearn: 0.0031442\ttotal: 17.4s\tremaining: 7.06s\n",
      "711:\tlearn: 0.0031403\ttotal: 17.4s\tremaining: 7.03s\n",
      "712:\tlearn: 0.0031358\ttotal: 17.4s\tremaining: 7.01s\n",
      "713:\tlearn: 0.0031344\ttotal: 17.4s\tremaining: 6.98s\n",
      "714:\tlearn: 0.0031325\ttotal: 17.4s\tremaining: 6.95s\n",
      "715:\tlearn: 0.0031266\ttotal: 17.5s\tremaining: 6.93s\n",
      "716:\tlearn: 0.0031237\ttotal: 17.5s\tremaining: 6.91s\n",
      "717:\tlearn: 0.0031191\ttotal: 17.5s\tremaining: 6.88s\n",
      "718:\tlearn: 0.0031169\ttotal: 17.5s\tremaining: 6.86s\n",
      "719:\tlearn: 0.0031072\ttotal: 17.6s\tremaining: 6.83s\n",
      "720:\tlearn: 0.0031044\ttotal: 17.6s\tremaining: 6.8s\n",
      "721:\tlearn: 0.0030977\ttotal: 17.6s\tremaining: 6.78s\n",
      "722:\tlearn: 0.0030923\ttotal: 17.6s\tremaining: 6.76s\n",
      "723:\tlearn: 0.0030884\ttotal: 17.7s\tremaining: 6.73s\n",
      "724:\tlearn: 0.0030805\ttotal: 17.7s\tremaining: 6.71s\n",
      "725:\tlearn: 0.0030788\ttotal: 17.7s\tremaining: 6.68s\n",
      "726:\tlearn: 0.0030749\ttotal: 17.7s\tremaining: 6.66s\n",
      "727:\tlearn: 0.0030708\ttotal: 17.8s\tremaining: 6.63s\n",
      "728:\tlearn: 0.0030692\ttotal: 17.8s\tremaining: 6.61s\n",
      "729:\tlearn: 0.0030641\ttotal: 17.8s\tremaining: 6.58s\n",
      "730:\tlearn: 0.0030638\ttotal: 17.8s\tremaining: 6.56s\n",
      "731:\tlearn: 0.0030618\ttotal: 17.8s\tremaining: 6.53s\n",
      "732:\tlearn: 0.0030614\ttotal: 17.9s\tremaining: 6.51s\n",
      "733:\tlearn: 0.0030578\ttotal: 17.9s\tremaining: 6.48s\n",
      "734:\tlearn: 0.0030550\ttotal: 17.9s\tremaining: 6.46s\n",
      "735:\tlearn: 0.0030526\ttotal: 17.9s\tremaining: 6.44s\n",
      "736:\tlearn: 0.0030450\ttotal: 18s\tremaining: 6.42s\n",
      "737:\tlearn: 0.0030425\ttotal: 18s\tremaining: 6.39s\n",
      "738:\tlearn: 0.0030359\ttotal: 18s\tremaining: 6.36s\n",
      "739:\tlearn: 0.0030319\ttotal: 18s\tremaining: 6.34s\n",
      "740:\tlearn: 0.0030288\ttotal: 18.1s\tremaining: 6.31s\n",
      "741:\tlearn: 0.0030251\ttotal: 18.1s\tremaining: 6.29s\n",
      "742:\tlearn: 0.0030238\ttotal: 18.1s\tremaining: 6.26s\n",
      "743:\tlearn: 0.0030151\ttotal: 18.1s\tremaining: 6.24s\n",
      "744:\tlearn: 0.0030118\ttotal: 18.2s\tremaining: 6.21s\n",
      "745:\tlearn: 0.0030107\ttotal: 18.2s\tremaining: 6.19s\n",
      "746:\tlearn: 0.0030048\ttotal: 18.2s\tremaining: 6.16s\n",
      "747:\tlearn: 0.0030036\ttotal: 18.2s\tremaining: 6.13s\n",
      "748:\tlearn: 0.0029988\ttotal: 18.2s\tremaining: 6.11s\n",
      "749:\tlearn: 0.0029939\ttotal: 18.3s\tremaining: 6.08s\n",
      "750:\tlearn: 0.0029928\ttotal: 18.3s\tremaining: 6.06s\n",
      "751:\tlearn: 0.0029891\ttotal: 18.3s\tremaining: 6.04s\n",
      "752:\tlearn: 0.0029778\ttotal: 18.3s\tremaining: 6.01s\n",
      "753:\tlearn: 0.0029717\ttotal: 18.3s\tremaining: 5.99s\n",
      "754:\tlearn: 0.0029655\ttotal: 18.4s\tremaining: 5.96s\n",
      "755:\tlearn: 0.0029599\ttotal: 18.4s\tremaining: 5.93s\n",
      "756:\tlearn: 0.0029596\ttotal: 18.4s\tremaining: 5.91s\n",
      "757:\tlearn: 0.0029534\ttotal: 18.4s\tremaining: 5.88s\n",
      "758:\tlearn: 0.0029501\ttotal: 18.5s\tremaining: 5.86s\n",
      "759:\tlearn: 0.0029481\ttotal: 18.5s\tremaining: 5.83s\n",
      "760:\tlearn: 0.0029463\ttotal: 18.5s\tremaining: 5.81s\n",
      "761:\tlearn: 0.0029431\ttotal: 18.5s\tremaining: 5.78s\n",
      "762:\tlearn: 0.0029421\ttotal: 18.5s\tremaining: 5.76s\n",
      "763:\tlearn: 0.0029387\ttotal: 18.6s\tremaining: 5.73s\n",
      "764:\tlearn: 0.0029344\ttotal: 18.6s\tremaining: 5.71s\n",
      "765:\tlearn: 0.0029303\ttotal: 18.6s\tremaining: 5.68s\n",
      "766:\tlearn: 0.0029259\ttotal: 18.6s\tremaining: 5.66s\n",
      "767:\tlearn: 0.0029236\ttotal: 18.6s\tremaining: 5.63s\n",
      "768:\tlearn: 0.0029197\ttotal: 18.7s\tremaining: 5.61s\n",
      "769:\tlearn: 0.0029152\ttotal: 18.7s\tremaining: 5.58s\n",
      "770:\tlearn: 0.0029097\ttotal: 18.7s\tremaining: 5.56s\n",
      "771:\tlearn: 0.0029072\ttotal: 18.7s\tremaining: 5.53s\n",
      "772:\tlearn: 0.0028975\ttotal: 18.7s\tremaining: 5.5s\n",
      "773:\tlearn: 0.0028937\ttotal: 18.8s\tremaining: 5.48s\n",
      "774:\tlearn: 0.0028921\ttotal: 18.8s\tremaining: 5.46s\n",
      "775:\tlearn: 0.0028857\ttotal: 18.8s\tremaining: 5.43s\n",
      "776:\tlearn: 0.0028853\ttotal: 18.8s\tremaining: 5.41s\n",
      "777:\tlearn: 0.0028821\ttotal: 18.9s\tremaining: 5.38s\n",
      "778:\tlearn: 0.0028732\ttotal: 18.9s\tremaining: 5.36s\n",
      "779:\tlearn: 0.0028717\ttotal: 18.9s\tremaining: 5.33s\n",
      "780:\tlearn: 0.0028708\ttotal: 18.9s\tremaining: 5.31s\n",
      "781:\tlearn: 0.0028670\ttotal: 19s\tremaining: 5.28s\n",
      "782:\tlearn: 0.0028642\ttotal: 19s\tremaining: 5.26s\n",
      "783:\tlearn: 0.0028634\ttotal: 19s\tremaining: 5.24s\n",
      "784:\tlearn: 0.0028621\ttotal: 19s\tremaining: 5.21s\n",
      "785:\tlearn: 0.0028610\ttotal: 19.1s\tremaining: 5.19s\n",
      "786:\tlearn: 0.0028575\ttotal: 19.1s\tremaining: 5.17s\n",
      "787:\tlearn: 0.0028520\ttotal: 19.1s\tremaining: 5.14s\n",
      "788:\tlearn: 0.0028439\ttotal: 19.1s\tremaining: 5.12s\n",
      "789:\tlearn: 0.0028318\ttotal: 19.2s\tremaining: 5.09s\n",
      "790:\tlearn: 0.0028292\ttotal: 19.2s\tremaining: 5.07s\n",
      "791:\tlearn: 0.0028246\ttotal: 19.2s\tremaining: 5.04s\n",
      "792:\tlearn: 0.0028201\ttotal: 19.2s\tremaining: 5.02s\n",
      "793:\tlearn: 0.0028107\ttotal: 19.2s\tremaining: 4.99s\n",
      "794:\tlearn: 0.0028085\ttotal: 19.3s\tremaining: 4.97s\n",
      "795:\tlearn: 0.0028044\ttotal: 19.3s\tremaining: 4.94s\n",
      "796:\tlearn: 0.0028024\ttotal: 19.3s\tremaining: 4.92s\n",
      "797:\tlearn: 0.0027942\ttotal: 19.3s\tremaining: 4.89s\n",
      "798:\tlearn: 0.0027933\ttotal: 19.4s\tremaining: 4.87s\n",
      "799:\tlearn: 0.0027904\ttotal: 19.4s\tremaining: 4.85s\n",
      "800:\tlearn: 0.0027840\ttotal: 19.4s\tremaining: 4.83s\n",
      "801:\tlearn: 0.0027809\ttotal: 19.4s\tremaining: 4.8s\n",
      "802:\tlearn: 0.0027783\ttotal: 19.5s\tremaining: 4.78s\n",
      "803:\tlearn: 0.0027761\ttotal: 19.5s\tremaining: 4.75s\n",
      "804:\tlearn: 0.0027744\ttotal: 19.5s\tremaining: 4.72s\n",
      "805:\tlearn: 0.0027712\ttotal: 19.5s\tremaining: 4.7s\n",
      "806:\tlearn: 0.0027672\ttotal: 19.6s\tremaining: 4.67s\n",
      "807:\tlearn: 0.0027644\ttotal: 19.6s\tremaining: 4.65s\n",
      "808:\tlearn: 0.0027490\ttotal: 19.6s\tremaining: 4.63s\n",
      "809:\tlearn: 0.0027478\ttotal: 19.6s\tremaining: 4.6s\n",
      "810:\tlearn: 0.0027358\ttotal: 19.6s\tremaining: 4.58s\n",
      "811:\tlearn: 0.0027349\ttotal: 19.7s\tremaining: 4.55s\n",
      "812:\tlearn: 0.0027310\ttotal: 19.7s\tremaining: 4.53s\n",
      "813:\tlearn: 0.0027259\ttotal: 19.7s\tremaining: 4.5s\n",
      "814:\tlearn: 0.0027212\ttotal: 19.7s\tremaining: 4.48s\n",
      "815:\tlearn: 0.0027167\ttotal: 19.7s\tremaining: 4.45s\n",
      "816:\tlearn: 0.0027134\ttotal: 19.8s\tremaining: 4.43s\n",
      "817:\tlearn: 0.0027073\ttotal: 19.8s\tremaining: 4.4s\n",
      "818:\tlearn: 0.0026983\ttotal: 19.8s\tremaining: 4.38s\n",
      "819:\tlearn: 0.0026897\ttotal: 19.8s\tremaining: 4.35s\n",
      "820:\tlearn: 0.0026889\ttotal: 19.9s\tremaining: 4.33s\n",
      "821:\tlearn: 0.0026850\ttotal: 19.9s\tremaining: 4.3s\n",
      "822:\tlearn: 0.0026799\ttotal: 19.9s\tremaining: 4.28s\n",
      "823:\tlearn: 0.0026744\ttotal: 19.9s\tremaining: 4.25s\n",
      "824:\tlearn: 0.0026741\ttotal: 19.9s\tremaining: 4.23s\n",
      "825:\tlearn: 0.0026713\ttotal: 20s\tremaining: 4.2s\n",
      "826:\tlearn: 0.0026711\ttotal: 20s\tremaining: 4.18s\n",
      "827:\tlearn: 0.0026683\ttotal: 20s\tremaining: 4.16s\n",
      "828:\tlearn: 0.0026657\ttotal: 20s\tremaining: 4.13s\n",
      "829:\tlearn: 0.0026639\ttotal: 20.1s\tremaining: 4.11s\n",
      "830:\tlearn: 0.0026612\ttotal: 20.1s\tremaining: 4.08s\n",
      "831:\tlearn: 0.0026579\ttotal: 20.1s\tremaining: 4.06s\n",
      "832:\tlearn: 0.0026535\ttotal: 20.1s\tremaining: 4.03s\n",
      "833:\tlearn: 0.0026507\ttotal: 20.1s\tremaining: 4.01s\n",
      "834:\tlearn: 0.0026418\ttotal: 20.2s\tremaining: 3.99s\n",
      "835:\tlearn: 0.0026339\ttotal: 20.2s\tremaining: 3.96s\n",
      "836:\tlearn: 0.0026308\ttotal: 20.2s\tremaining: 3.94s\n",
      "837:\tlearn: 0.0026298\ttotal: 20.3s\tremaining: 3.92s\n",
      "838:\tlearn: 0.0026291\ttotal: 20.3s\tremaining: 3.89s\n",
      "839:\tlearn: 0.0026288\ttotal: 20.3s\tremaining: 3.87s\n",
      "840:\tlearn: 0.0026241\ttotal: 20.3s\tremaining: 3.84s\n",
      "841:\tlearn: 0.0026197\ttotal: 20.3s\tremaining: 3.81s\n",
      "842:\tlearn: 0.0026122\ttotal: 20.4s\tremaining: 3.79s\n",
      "843:\tlearn: 0.0026082\ttotal: 20.4s\tremaining: 3.77s\n",
      "844:\tlearn: 0.0026067\ttotal: 20.4s\tremaining: 3.74s\n",
      "845:\tlearn: 0.0026005\ttotal: 20.4s\tremaining: 3.72s\n",
      "846:\tlearn: 0.0025966\ttotal: 20.4s\tremaining: 3.69s\n",
      "847:\tlearn: 0.0025925\ttotal: 20.5s\tremaining: 3.67s\n",
      "848:\tlearn: 0.0025909\ttotal: 20.5s\tremaining: 3.64s\n",
      "849:\tlearn: 0.0025900\ttotal: 20.5s\tremaining: 3.62s\n",
      "850:\tlearn: 0.0025875\ttotal: 20.5s\tremaining: 3.59s\n",
      "851:\tlearn: 0.0025852\ttotal: 20.6s\tremaining: 3.57s\n",
      "852:\tlearn: 0.0025810\ttotal: 20.6s\tremaining: 3.55s\n",
      "853:\tlearn: 0.0025771\ttotal: 20.6s\tremaining: 3.52s\n",
      "854:\tlearn: 0.0025758\ttotal: 20.6s\tremaining: 3.5s\n",
      "855:\tlearn: 0.0025737\ttotal: 20.6s\tremaining: 3.47s\n",
      "856:\tlearn: 0.0025706\ttotal: 20.7s\tremaining: 3.45s\n",
      "857:\tlearn: 0.0025665\ttotal: 20.7s\tremaining: 3.42s\n",
      "858:\tlearn: 0.0025605\ttotal: 20.7s\tremaining: 3.4s\n",
      "859:\tlearn: 0.0025597\ttotal: 20.7s\tremaining: 3.37s\n",
      "860:\tlearn: 0.0025585\ttotal: 20.7s\tremaining: 3.35s\n",
      "861:\tlearn: 0.0025551\ttotal: 20.8s\tremaining: 3.32s\n",
      "862:\tlearn: 0.0025485\ttotal: 20.8s\tremaining: 3.3s\n",
      "863:\tlearn: 0.0025461\ttotal: 20.8s\tremaining: 3.27s\n",
      "864:\tlearn: 0.0025446\ttotal: 20.8s\tremaining: 3.25s\n",
      "865:\tlearn: 0.0025433\ttotal: 20.8s\tremaining: 3.23s\n",
      "866:\tlearn: 0.0025397\ttotal: 20.9s\tremaining: 3.2s\n",
      "867:\tlearn: 0.0025382\ttotal: 20.9s\tremaining: 3.18s\n",
      "868:\tlearn: 0.0025376\ttotal: 20.9s\tremaining: 3.15s\n",
      "869:\tlearn: 0.0025357\ttotal: 20.9s\tremaining: 3.13s\n",
      "870:\tlearn: 0.0025347\ttotal: 21s\tremaining: 3.1s\n",
      "871:\tlearn: 0.0025339\ttotal: 21s\tremaining: 3.08s\n",
      "872:\tlearn: 0.0025320\ttotal: 21s\tremaining: 3.05s\n",
      "873:\tlearn: 0.0025304\ttotal: 21s\tremaining: 3.03s\n",
      "874:\tlearn: 0.0025228\ttotal: 21s\tremaining: 3s\n",
      "875:\tlearn: 0.0025185\ttotal: 21.1s\tremaining: 2.98s\n",
      "876:\tlearn: 0.0025174\ttotal: 21.1s\tremaining: 2.96s\n",
      "877:\tlearn: 0.0025142\ttotal: 21.1s\tremaining: 2.93s\n",
      "878:\tlearn: 0.0025138\ttotal: 21.1s\tremaining: 2.91s\n",
      "879:\tlearn: 0.0025131\ttotal: 21.2s\tremaining: 2.88s\n",
      "880:\tlearn: 0.0025124\ttotal: 21.2s\tremaining: 2.86s\n",
      "881:\tlearn: 0.0025117\ttotal: 21.2s\tremaining: 2.83s\n",
      "882:\tlearn: 0.0025104\ttotal: 21.2s\tremaining: 2.81s\n",
      "883:\tlearn: 0.0025070\ttotal: 21.2s\tremaining: 2.79s\n",
      "884:\tlearn: 0.0025036\ttotal: 21.3s\tremaining: 2.76s\n",
      "885:\tlearn: 0.0025034\ttotal: 21.3s\tremaining: 2.74s\n",
      "886:\tlearn: 0.0025002\ttotal: 21.3s\tremaining: 2.72s\n",
      "887:\tlearn: 0.0024980\ttotal: 21.3s\tremaining: 2.69s\n",
      "888:\tlearn: 0.0024904\ttotal: 21.4s\tremaining: 2.67s\n",
      "889:\tlearn: 0.0024890\ttotal: 21.4s\tremaining: 2.64s\n",
      "890:\tlearn: 0.0024874\ttotal: 21.4s\tremaining: 2.62s\n",
      "891:\tlearn: 0.0024832\ttotal: 21.4s\tremaining: 2.6s\n",
      "892:\tlearn: 0.0024732\ttotal: 21.5s\tremaining: 2.57s\n",
      "893:\tlearn: 0.0024670\ttotal: 21.5s\tremaining: 2.55s\n",
      "894:\tlearn: 0.0024664\ttotal: 21.5s\tremaining: 2.52s\n",
      "895:\tlearn: 0.0024651\ttotal: 21.5s\tremaining: 2.5s\n",
      "896:\tlearn: 0.0024644\ttotal: 21.6s\tremaining: 2.47s\n",
      "897:\tlearn: 0.0024595\ttotal: 21.6s\tremaining: 2.45s\n",
      "898:\tlearn: 0.0024590\ttotal: 21.6s\tremaining: 2.43s\n",
      "899:\tlearn: 0.0024556\ttotal: 21.6s\tremaining: 2.4s\n",
      "900:\tlearn: 0.0024536\ttotal: 21.6s\tremaining: 2.38s\n",
      "901:\tlearn: 0.0024502\ttotal: 21.7s\tremaining: 2.35s\n",
      "902:\tlearn: 0.0024484\ttotal: 21.7s\tremaining: 2.33s\n",
      "903:\tlearn: 0.0024462\ttotal: 21.7s\tremaining: 2.3s\n",
      "904:\tlearn: 0.0024442\ttotal: 21.7s\tremaining: 2.28s\n",
      "905:\tlearn: 0.0024261\ttotal: 21.8s\tremaining: 2.26s\n",
      "906:\tlearn: 0.0024243\ttotal: 21.8s\tremaining: 2.23s\n",
      "907:\tlearn: 0.0024193\ttotal: 21.8s\tremaining: 2.21s\n",
      "908:\tlearn: 0.0024161\ttotal: 21.8s\tremaining: 2.18s\n",
      "909:\tlearn: 0.0024125\ttotal: 21.8s\tremaining: 2.16s\n",
      "910:\tlearn: 0.0024085\ttotal: 21.9s\tremaining: 2.13s\n",
      "911:\tlearn: 0.0024036\ttotal: 21.9s\tremaining: 2.11s\n",
      "912:\tlearn: 0.0024028\ttotal: 21.9s\tremaining: 2.09s\n",
      "913:\tlearn: 0.0024023\ttotal: 21.9s\tremaining: 2.06s\n",
      "914:\tlearn: 0.0023999\ttotal: 22s\tremaining: 2.04s\n",
      "915:\tlearn: 0.0023993\ttotal: 22s\tremaining: 2.01s\n",
      "916:\tlearn: 0.0023975\ttotal: 22s\tremaining: 1.99s\n",
      "917:\tlearn: 0.0023952\ttotal: 22s\tremaining: 1.97s\n",
      "918:\tlearn: 0.0023922\ttotal: 22s\tremaining: 1.94s\n",
      "919:\tlearn: 0.0023868\ttotal: 22s\tremaining: 1.92s\n",
      "920:\tlearn: 0.0023823\ttotal: 22.1s\tremaining: 1.89s\n",
      "921:\tlearn: 0.0023743\ttotal: 22.1s\tremaining: 1.87s\n",
      "922:\tlearn: 0.0023712\ttotal: 22.1s\tremaining: 1.84s\n",
      "923:\tlearn: 0.0023667\ttotal: 22.1s\tremaining: 1.82s\n",
      "924:\tlearn: 0.0023620\ttotal: 22.2s\tremaining: 1.8s\n",
      "925:\tlearn: 0.0023581\ttotal: 22.2s\tremaining: 1.77s\n",
      "926:\tlearn: 0.0023570\ttotal: 22.2s\tremaining: 1.75s\n",
      "927:\tlearn: 0.0023553\ttotal: 22.2s\tremaining: 1.72s\n",
      "928:\tlearn: 0.0023514\ttotal: 22.2s\tremaining: 1.7s\n",
      "929:\tlearn: 0.0023498\ttotal: 22.3s\tremaining: 1.68s\n",
      "930:\tlearn: 0.0023452\ttotal: 22.3s\tremaining: 1.65s\n",
      "931:\tlearn: 0.0023428\ttotal: 22.3s\tremaining: 1.63s\n",
      "932:\tlearn: 0.0023396\ttotal: 22.3s\tremaining: 1.6s\n",
      "933:\tlearn: 0.0023375\ttotal: 22.4s\tremaining: 1.58s\n",
      "934:\tlearn: 0.0023318\ttotal: 22.4s\tremaining: 1.56s\n",
      "935:\tlearn: 0.0023248\ttotal: 22.4s\tremaining: 1.53s\n",
      "936:\tlearn: 0.0023230\ttotal: 22.5s\tremaining: 1.51s\n",
      "937:\tlearn: 0.0023200\ttotal: 22.5s\tremaining: 1.49s\n",
      "938:\tlearn: 0.0023138\ttotal: 22.5s\tremaining: 1.46s\n",
      "939:\tlearn: 0.0023113\ttotal: 22.5s\tremaining: 1.44s\n",
      "940:\tlearn: 0.0023074\ttotal: 22.5s\tremaining: 1.41s\n",
      "941:\tlearn: 0.0023029\ttotal: 22.6s\tremaining: 1.39s\n",
      "942:\tlearn: 0.0023007\ttotal: 22.6s\tremaining: 1.36s\n",
      "943:\tlearn: 0.0022951\ttotal: 22.6s\tremaining: 1.34s\n",
      "944:\tlearn: 0.0022944\ttotal: 22.6s\tremaining: 1.32s\n",
      "945:\tlearn: 0.0022925\ttotal: 22.6s\tremaining: 1.29s\n",
      "946:\tlearn: 0.0022881\ttotal: 22.7s\tremaining: 1.27s\n",
      "947:\tlearn: 0.0022854\ttotal: 22.7s\tremaining: 1.25s\n",
      "948:\tlearn: 0.0022769\ttotal: 22.7s\tremaining: 1.22s\n",
      "949:\tlearn: 0.0022737\ttotal: 22.7s\tremaining: 1.2s\n",
      "950:\tlearn: 0.0022713\ttotal: 22.8s\tremaining: 1.17s\n",
      "951:\tlearn: 0.0022678\ttotal: 22.8s\tremaining: 1.15s\n",
      "952:\tlearn: 0.0022640\ttotal: 22.8s\tremaining: 1.12s\n",
      "953:\tlearn: 0.0022568\ttotal: 22.8s\tremaining: 1.1s\n",
      "954:\tlearn: 0.0022545\ttotal: 22.9s\tremaining: 1.08s\n",
      "955:\tlearn: 0.0022515\ttotal: 22.9s\tremaining: 1.05s\n",
      "956:\tlearn: 0.0022470\ttotal: 22.9s\tremaining: 1.03s\n",
      "957:\tlearn: 0.0022449\ttotal: 22.9s\tremaining: 1s\n",
      "958:\tlearn: 0.0022419\ttotal: 22.9s\tremaining: 981ms\n",
      "959:\tlearn: 0.0022369\ttotal: 23s\tremaining: 957ms\n",
      "960:\tlearn: 0.0022358\ttotal: 23s\tremaining: 933ms\n",
      "961:\tlearn: 0.0022307\ttotal: 23s\tremaining: 909ms\n",
      "962:\tlearn: 0.0022280\ttotal: 23s\tremaining: 885ms\n",
      "963:\tlearn: 0.0022261\ttotal: 23.1s\tremaining: 861ms\n",
      "964:\tlearn: 0.0022245\ttotal: 23.1s\tremaining: 837ms\n",
      "965:\tlearn: 0.0022182\ttotal: 23.1s\tremaining: 813ms\n",
      "966:\tlearn: 0.0022173\ttotal: 23.1s\tremaining: 789ms\n",
      "967:\tlearn: 0.0022152\ttotal: 23.1s\tremaining: 765ms\n",
      "968:\tlearn: 0.0022114\ttotal: 23.2s\tremaining: 741ms\n",
      "969:\tlearn: 0.0022102\ttotal: 23.2s\tremaining: 717ms\n",
      "970:\tlearn: 0.0022072\ttotal: 23.2s\tremaining: 693ms\n",
      "971:\tlearn: 0.0022016\ttotal: 23.2s\tremaining: 669ms\n",
      "972:\tlearn: 0.0022003\ttotal: 23.2s\tremaining: 645ms\n",
      "973:\tlearn: 0.0021995\ttotal: 23.3s\tremaining: 621ms\n",
      "974:\tlearn: 0.0021982\ttotal: 23.3s\tremaining: 597ms\n",
      "975:\tlearn: 0.0021861\ttotal: 23.3s\tremaining: 574ms\n",
      "976:\tlearn: 0.0021832\ttotal: 23.4s\tremaining: 550ms\n",
      "977:\tlearn: 0.0021809\ttotal: 23.4s\tremaining: 526ms\n",
      "978:\tlearn: 0.0021795\ttotal: 23.4s\tremaining: 502ms\n",
      "979:\tlearn: 0.0021759\ttotal: 23.4s\tremaining: 478ms\n",
      "980:\tlearn: 0.0021745\ttotal: 23.5s\tremaining: 454ms\n",
      "981:\tlearn: 0.0021729\ttotal: 23.5s\tremaining: 431ms\n",
      "982:\tlearn: 0.0021690\ttotal: 23.5s\tremaining: 407ms\n",
      "983:\tlearn: 0.0021676\ttotal: 23.5s\tremaining: 383ms\n",
      "984:\tlearn: 0.0021652\ttotal: 23.6s\tremaining: 359ms\n",
      "985:\tlearn: 0.0021640\ttotal: 23.6s\tremaining: 335ms\n",
      "986:\tlearn: 0.0021627\ttotal: 23.7s\tremaining: 312ms\n",
      "987:\tlearn: 0.0021569\ttotal: 23.7s\tremaining: 288ms\n",
      "988:\tlearn: 0.0021512\ttotal: 23.7s\tremaining: 264ms\n",
      "989:\tlearn: 0.0021497\ttotal: 23.7s\tremaining: 240ms\n",
      "990:\tlearn: 0.0021371\ttotal: 23.8s\tremaining: 216ms\n",
      "991:\tlearn: 0.0021344\ttotal: 23.8s\tremaining: 192ms\n",
      "992:\tlearn: 0.0021333\ttotal: 23.9s\tremaining: 168ms\n",
      "993:\tlearn: 0.0021309\ttotal: 23.9s\tremaining: 144ms\n",
      "994:\tlearn: 0.0021260\ttotal: 23.9s\tremaining: 120ms\n",
      "995:\tlearn: 0.0021249\ttotal: 23.9s\tremaining: 96.2ms\n",
      "996:\tlearn: 0.0021240\ttotal: 24s\tremaining: 72.2ms\n",
      "997:\tlearn: 0.0021233\ttotal: 24s\tremaining: 48.1ms\n",
      "998:\tlearn: 0.0021205\ttotal: 24s\tremaining: 24.1ms\n",
      "999:\tlearn: 0.0021157\ttotal: 24.1s\tremaining: 0us\n",
      "[LightGBM] [Info] Number of positive: 1258, number of negative: 67396\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3475\n",
      "[LightGBM] [Info] Number of data points in the train set: 68654, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018324 -> initscore=-3.981063\n",
      "[LightGBM] [Info] Start training from score -3.981063\n"
     ]
    }
   ],
   "source": [
    "model_benchmarching.average_top_5_f1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>SVC</th>\n",
       "      <th>KNeighbors</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>LGBM</th>\n",
       "      <th>XGB</th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>RGF</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>Bagging</th>\n",
       "      <th>Voting</th>\n",
       "      <th>Stacking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.981793</td>\n",
       "      <td>0.996431</td>\n",
       "      <td>0.981778</td>\n",
       "      <td>0.981574</td>\n",
       "      <td>0.995135</td>\n",
       "      <td>0.995980</td>\n",
       "      <td>0.995849</td>\n",
       "      <td>0.996082</td>\n",
       "      <td>0.992455</td>\n",
       "      <td>0.994567</td>\n",
       "      <td>0.991741</td>\n",
       "      <td>0.995849</td>\n",
       "      <td>0.996140</td>\n",
       "      <td>0.996373</td>\n",
       "      <td>0.996417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.071341</td>\n",
       "      <td>0.899304</td>\n",
       "      <td>0.026430</td>\n",
       "      <td>0.206664</td>\n",
       "      <td>0.868237</td>\n",
       "      <td>0.887061</td>\n",
       "      <td>0.884052</td>\n",
       "      <td>0.889951</td>\n",
       "      <td>0.772683</td>\n",
       "      <td>0.840594</td>\n",
       "      <td>0.757516</td>\n",
       "      <td>0.879893</td>\n",
       "      <td>0.890860</td>\n",
       "      <td>0.897750</td>\n",
       "      <td>0.898787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.573600</td>\n",
       "      <td>0.931135</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.488840</td>\n",
       "      <td>0.863261</td>\n",
       "      <td>0.914070</td>\n",
       "      <td>0.905984</td>\n",
       "      <td>0.916610</td>\n",
       "      <td>0.862548</td>\n",
       "      <td>0.908850</td>\n",
       "      <td>0.819298</td>\n",
       "      <td>0.936353</td>\n",
       "      <td>0.923973</td>\n",
       "      <td>0.928781</td>\n",
       "      <td>0.931944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.038165</td>\n",
       "      <td>0.869633</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.131152</td>\n",
       "      <td>0.873604</td>\n",
       "      <td>0.861677</td>\n",
       "      <td>0.863283</td>\n",
       "      <td>0.864858</td>\n",
       "      <td>0.700323</td>\n",
       "      <td>0.782220</td>\n",
       "      <td>0.705088</td>\n",
       "      <td>0.829896</td>\n",
       "      <td>0.860083</td>\n",
       "      <td>0.868829</td>\n",
       "      <td>0.868039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.518786</td>\n",
       "      <td>0.934215</td>\n",
       "      <td>0.506683</td>\n",
       "      <td>0.564300</td>\n",
       "      <td>0.935504</td>\n",
       "      <td>0.930082</td>\n",
       "      <td>0.930803</td>\n",
       "      <td>0.931695</td>\n",
       "      <td>0.849115</td>\n",
       "      <td>0.890376</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.914421</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.933792</td>\n",
       "      <td>0.933426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LogisticRegression  RandomForest       SVC  KNeighbors  \\\n",
       "accuracy             0.981793      0.996431  0.981778    0.981574   \n",
       "f1                   0.071341      0.899304  0.026430    0.206664   \n",
       "precision            0.573600      0.931135  0.650000    0.488840   \n",
       "recall               0.038165      0.869633  0.013514    0.131152   \n",
       "roc                  0.518786      0.934215  0.506683    0.564300   \n",
       "\n",
       "           DecisionTree      LGBM       XGB  CatBoost       RGF  \\\n",
       "accuracy       0.995135  0.995980  0.995849  0.996082  0.992455   \n",
       "f1             0.868237  0.887061  0.884052  0.889951  0.772683   \n",
       "precision      0.863261  0.914070  0.905984  0.916610  0.862548   \n",
       "recall         0.873604  0.861677  0.863283  0.864858  0.700323   \n",
       "roc            0.935504  0.930082  0.930803  0.931695  0.849115   \n",
       "\n",
       "           GradientBoosting  AdaBoost  ExtraTrees   Bagging    Voting  \\\n",
       "accuracy           0.994567  0.991741    0.995849  0.996140  0.996373   \n",
       "f1                 0.840594  0.757516    0.879893  0.890860  0.897750   \n",
       "precision          0.908850  0.819298    0.936353  0.923973  0.928781   \n",
       "recall             0.782220  0.705088    0.829896  0.860083  0.868829   \n",
       "roc                0.890376  0.851090    0.914421  0.929381  0.933792   \n",
       "\n",
       "           Stacking  \n",
       "accuracy   0.996417  \n",
       "f1         0.898787  \n",
       "precision  0.931944  \n",
       "recall     0.868039  \n",
       "roc        0.933426  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_benchmarching.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>SVC</th>\n",
       "      <th>KNeighbors</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>LGBM</th>\n",
       "      <th>XGB</th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>RGF</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>Bagging</th>\n",
       "      <th>Voting</th>\n",
       "      <th>Stacking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.981793</td>\n",
       "      <td>0.996431</td>\n",
       "      <td>0.981778</td>\n",
       "      <td>0.981574</td>\n",
       "      <td>0.995135</td>\n",
       "      <td>0.995980</td>\n",
       "      <td>0.995849</td>\n",
       "      <td>0.996082</td>\n",
       "      <td>0.992455</td>\n",
       "      <td>0.994567</td>\n",
       "      <td>0.991741</td>\n",
       "      <td>0.995849</td>\n",
       "      <td>0.996140</td>\n",
       "      <td>0.996373</td>\n",
       "      <td>0.996417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.071341</td>\n",
       "      <td>0.899304</td>\n",
       "      <td>0.026430</td>\n",
       "      <td>0.206664</td>\n",
       "      <td>0.868237</td>\n",
       "      <td>0.887061</td>\n",
       "      <td>0.884052</td>\n",
       "      <td>0.889951</td>\n",
       "      <td>0.772683</td>\n",
       "      <td>0.840594</td>\n",
       "      <td>0.757516</td>\n",
       "      <td>0.879893</td>\n",
       "      <td>0.890860</td>\n",
       "      <td>0.897750</td>\n",
       "      <td>0.898787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.573600</td>\n",
       "      <td>0.931135</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.488840</td>\n",
       "      <td>0.863261</td>\n",
       "      <td>0.914070</td>\n",
       "      <td>0.905984</td>\n",
       "      <td>0.916610</td>\n",
       "      <td>0.862548</td>\n",
       "      <td>0.908850</td>\n",
       "      <td>0.819298</td>\n",
       "      <td>0.936353</td>\n",
       "      <td>0.923973</td>\n",
       "      <td>0.928781</td>\n",
       "      <td>0.931944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.038165</td>\n",
       "      <td>0.869633</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.131152</td>\n",
       "      <td>0.873604</td>\n",
       "      <td>0.861677</td>\n",
       "      <td>0.863283</td>\n",
       "      <td>0.864858</td>\n",
       "      <td>0.700323</td>\n",
       "      <td>0.782220</td>\n",
       "      <td>0.705088</td>\n",
       "      <td>0.829896</td>\n",
       "      <td>0.860083</td>\n",
       "      <td>0.868829</td>\n",
       "      <td>0.868039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.518786</td>\n",
       "      <td>0.934215</td>\n",
       "      <td>0.506683</td>\n",
       "      <td>0.564300</td>\n",
       "      <td>0.935504</td>\n",
       "      <td>0.930082</td>\n",
       "      <td>0.930803</td>\n",
       "      <td>0.931695</td>\n",
       "      <td>0.849115</td>\n",
       "      <td>0.890376</td>\n",
       "      <td>0.851090</td>\n",
       "      <td>0.914421</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.933792</td>\n",
       "      <td>0.933426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LogisticRegression  RandomForest       SVC  KNeighbors  \\\n",
       "accuracy             0.981793      0.996431  0.981778    0.981574   \n",
       "f1                   0.071341      0.899304  0.026430    0.206664   \n",
       "precision            0.573600      0.931135  0.650000    0.488840   \n",
       "recall               0.038165      0.869633  0.013514    0.131152   \n",
       "roc                  0.518786      0.934215  0.506683    0.564300   \n",
       "\n",
       "           DecisionTree      LGBM       XGB  CatBoost       RGF  \\\n",
       "accuracy       0.995135  0.995980  0.995849  0.996082  0.992455   \n",
       "f1             0.868237  0.887061  0.884052  0.889951  0.772683   \n",
       "precision      0.863261  0.914070  0.905984  0.916610  0.862548   \n",
       "recall         0.873604  0.861677  0.863283  0.864858  0.700323   \n",
       "roc            0.935504  0.930082  0.930803  0.931695  0.849115   \n",
       "\n",
       "           GradientBoosting  AdaBoost  ExtraTrees   Bagging    Voting  \\\n",
       "accuracy           0.994567  0.991741    0.995849  0.996140  0.996373   \n",
       "f1                 0.840594  0.757516    0.879893  0.890860  0.897750   \n",
       "precision          0.908850  0.819298    0.936353  0.923973  0.928781   \n",
       "recall             0.782220  0.705088    0.829896  0.860083  0.868829   \n",
       "roc                0.890376  0.851090    0.914421  0.929381  0.933792   \n",
       "\n",
       "           Stacking  \n",
       "accuracy   0.996417  \n",
       "f1         0.898787  \n",
       "precision  0.931944  \n",
       "recall     0.868039  \n",
       "roc        0.933426  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_benchmarching.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RandomForest',\n",
       "  {'accuracy': 0.9964313741777489,\n",
       "   'f1': 0.8993038313374171,\n",
       "   'precision': 0.9311353724932424,\n",
       "   'recall': 0.8696325807879592,\n",
       "   'roc': 0.9342153633116714}),\n",
       " ('Stacking',\n",
       "  {'accuracy': 0.9964168096570759,\n",
       "   'f1': 0.8987871532919749,\n",
       "   'precision': 0.9319438452741942,\n",
       "   'recall': 0.8680389552899512,\n",
       "   'roc': 0.9334259678595593}),\n",
       " ('Voting',\n",
       "  {'accuracy': 0.9963731150341998,\n",
       "   'f1': 0.8977499724957301,\n",
       "   'precision': 0.9287805289888096,\n",
       "   'recall': 0.8688294441282489,\n",
       "   'roc': 0.9337915386882039}),\n",
       " ('Bagging',\n",
       "  {'accuracy': 0.9961400529994091,\n",
       "   'f1': 0.8908604827344678,\n",
       "   'precision': 0.9239733175816618,\n",
       "   'recall': 0.8600834756213243,\n",
       "   'roc': 0.9293814591444084}),\n",
       " ('CatBoost',\n",
       "  {'accuracy': 0.9960818023427247,\n",
       "   'f1': 0.8899514558091528,\n",
       "   'precision': 0.9166095792450534,\n",
       "   'recall': 0.8648580282046417,\n",
       "   'roc': 0.931694549258338}),\n",
       " ('LGBM',\n",
       "  {'accuracy': 0.9959798432720088,\n",
       "   'f1': 0.8870613083827207,\n",
       "   'precision': 0.9140704894436098,\n",
       "   'recall': 0.8616771011193322,\n",
       "   'roc': 0.9300818294220706}),\n",
       " ('XGB',\n",
       "  {'accuracy': 0.9958487487947988,\n",
       "   'f1': 0.8840524804772567,\n",
       "   'precision': 0.9059839643109455,\n",
       "   'recall': 0.8632833744387529,\n",
       "   'roc': 0.9308033576538561}),\n",
       " ('ExtraTrees',\n",
       "  {'accuracy': 0.9958487487947989,\n",
       "   'f1': 0.8798929067697321,\n",
       "   'precision': 0.9363532913444418,\n",
       "   'recall': 0.8298962878644154,\n",
       "   'roc': 0.9144214063298313}),\n",
       " ('DecisionTree',\n",
       "  {'accuracy': 0.9951350289346392,\n",
       "   'f1': 0.8682368499876969,\n",
       "   'precision': 0.8632610877695601,\n",
       "   'recall': 0.8736039967115664,\n",
       "   'roc': 0.9355037000687236}),\n",
       " ('GradientBoosting',\n",
       "  {'accuracy': 0.9945669648897878,\n",
       "   'f1': 0.8405936993600547,\n",
       "   'precision': 0.9088498623566525,\n",
       "   'recall': 0.7822203250490103,\n",
       "   'roc': 0.890375696579788}),\n",
       " ('RGF',\n",
       "  {'accuracy': 0.9924549194986406,\n",
       "   'f1': 0.7726830409330959,\n",
       "   'precision': 0.8625484185027259,\n",
       "   'recall': 0.7003225194460254,\n",
       "   'roc': 0.8491152012647847}),\n",
       " ('AdaBoost',\n",
       "  {'accuracy': 0.9917411879690418,\n",
       "   'f1': 0.7575159817811966,\n",
       "   'precision': 0.8192979627833031,\n",
       "   'recall': 0.7050875861632833,\n",
       "   'roc': 0.8510897067933326}),\n",
       " ('KNeighbors',\n",
       "  {'accuracy': 0.9815742762706785,\n",
       "   'f1': 0.20666422041215377,\n",
       "   'precision': 0.4888401342361607,\n",
       "   'recall': 0.13115158413963196,\n",
       "   'roc': 0.5642997539289383}),\n",
       " ('LogisticRegression',\n",
       "  {'accuracy': 0.9817927578719251,\n",
       "   'f1': 0.07134138654747303,\n",
       "   'precision': 0.5735995067883614,\n",
       "   'recall': 0.03816480111300828,\n",
       "   'roc': 0.5187856470397136}),\n",
       " ('SVC',\n",
       "  {'accuracy': 0.9817781922903942,\n",
       "   'f1': 0.026430018277338586,\n",
       "   'precision': 0.65,\n",
       "   'recall': 0.013514197179535826,\n",
       "   'roc': 0.5066829096602032})]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(model_benchmarching.results.items(), key=lambda x: x[1][\"f1\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1258, number of negative: 67396\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3490\n",
      "[LightGBM] [Info] Number of data points in the train set: 68654, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.018324 -> initscore=-3.981063\n",
      "[LightGBM] [Info] Start training from score -3.981063\n",
      "Learning rate set to 0.062689\n",
      "0:\tlearn: 0.4983636\ttotal: 75.2ms\tremaining: 1m 15s\n",
      "1:\tlearn: 0.3543725\ttotal: 168ms\tremaining: 1m 23s\n",
      "2:\tlearn: 0.2505180\ttotal: 232ms\tremaining: 1m 17s\n",
      "3:\tlearn: 0.1990540\ttotal: 282ms\tremaining: 1m 10s\n",
      "4:\tlearn: 0.1480551\ttotal: 341ms\tremaining: 1m 7s\n",
      "5:\tlearn: 0.1160532\ttotal: 368ms\tremaining: 1m\n",
      "6:\tlearn: 0.0902537\ttotal: 397ms\tremaining: 56.3s\n",
      "7:\tlearn: 0.0719874\ttotal: 423ms\tremaining: 52.5s\n",
      "8:\tlearn: 0.0593447\ttotal: 455ms\tremaining: 50.1s\n",
      "9:\tlearn: 0.0504864\ttotal: 478ms\tremaining: 47.4s\n",
      "10:\tlearn: 0.0437542\ttotal: 498ms\tremaining: 44.8s\n",
      "11:\tlearn: 0.0387290\ttotal: 518ms\tremaining: 42.6s\n",
      "12:\tlearn: 0.0348410\ttotal: 540ms\tremaining: 41s\n",
      "13:\tlearn: 0.0330825\ttotal: 563ms\tremaining: 39.6s\n",
      "14:\tlearn: 0.0308264\ttotal: 592ms\tremaining: 38.9s\n",
      "15:\tlearn: 0.0287781\ttotal: 621ms\tremaining: 38.2s\n",
      "16:\tlearn: 0.0272267\ttotal: 654ms\tremaining: 37.8s\n",
      "17:\tlearn: 0.0255713\ttotal: 676ms\tremaining: 36.9s\n",
      "18:\tlearn: 0.0244395\ttotal: 694ms\tremaining: 35.8s\n",
      "19:\tlearn: 0.0235931\ttotal: 710ms\tremaining: 34.8s\n",
      "20:\tlearn: 0.0227882\ttotal: 726ms\tremaining: 33.9s\n",
      "21:\tlearn: 0.0219059\ttotal: 743ms\tremaining: 33s\n",
      "22:\tlearn: 0.0215778\ttotal: 759ms\tremaining: 32.3s\n",
      "23:\tlearn: 0.0211121\ttotal: 775ms\tremaining: 31.5s\n",
      "24:\tlearn: 0.0205451\ttotal: 799ms\tremaining: 31.2s\n",
      "25:\tlearn: 0.0201893\ttotal: 817ms\tremaining: 30.6s\n",
      "26:\tlearn: 0.0199887\ttotal: 833ms\tremaining: 30s\n",
      "27:\tlearn: 0.0197218\ttotal: 850ms\tremaining: 29.5s\n",
      "28:\tlearn: 0.0194930\ttotal: 866ms\tremaining: 29s\n",
      "29:\tlearn: 0.0193100\ttotal: 884ms\tremaining: 28.6s\n",
      "30:\tlearn: 0.0191031\ttotal: 901ms\tremaining: 28.2s\n",
      "31:\tlearn: 0.0189822\ttotal: 917ms\tremaining: 27.8s\n",
      "32:\tlearn: 0.0187666\ttotal: 936ms\tremaining: 27.4s\n",
      "33:\tlearn: 0.0182898\ttotal: 957ms\tremaining: 27.2s\n",
      "34:\tlearn: 0.0181820\ttotal: 974ms\tremaining: 26.9s\n",
      "35:\tlearn: 0.0178932\ttotal: 992ms\tremaining: 26.6s\n",
      "36:\tlearn: 0.0177866\ttotal: 1.01s\tremaining: 26.2s\n",
      "37:\tlearn: 0.0177083\ttotal: 1.02s\tremaining: 25.9s\n",
      "38:\tlearn: 0.0176657\ttotal: 1.04s\tremaining: 25.7s\n",
      "39:\tlearn: 0.0175567\ttotal: 1.06s\tremaining: 25.4s\n",
      "40:\tlearn: 0.0175136\ttotal: 1.07s\tremaining: 25.1s\n",
      "41:\tlearn: 0.0173414\ttotal: 1.1s\tremaining: 25s\n",
      "42:\tlearn: 0.0172581\ttotal: 1.11s\tremaining: 24.8s\n",
      "43:\tlearn: 0.0168967\ttotal: 1.13s\tremaining: 24.6s\n",
      "44:\tlearn: 0.0166097\ttotal: 1.15s\tremaining: 24.4s\n",
      "45:\tlearn: 0.0162660\ttotal: 1.17s\tremaining: 24.2s\n",
      "46:\tlearn: 0.0159807\ttotal: 1.18s\tremaining: 24s\n",
      "47:\tlearn: 0.0157195\ttotal: 1.2s\tremaining: 23.9s\n",
      "48:\tlearn: 0.0155017\ttotal: 1.22s\tremaining: 23.7s\n",
      "49:\tlearn: 0.0153257\ttotal: 1.24s\tremaining: 23.5s\n",
      "50:\tlearn: 0.0151553\ttotal: 1.25s\tremaining: 23.4s\n",
      "51:\tlearn: 0.0150110\ttotal: 1.27s\tremaining: 23.2s\n",
      "52:\tlearn: 0.0148567\ttotal: 1.3s\tremaining: 23.2s\n",
      "53:\tlearn: 0.0147763\ttotal: 1.31s\tremaining: 23s\n",
      "54:\tlearn: 0.0146361\ttotal: 1.33s\tremaining: 22.9s\n",
      "55:\tlearn: 0.0145806\ttotal: 1.35s\tremaining: 22.7s\n",
      "56:\tlearn: 0.0144493\ttotal: 1.37s\tremaining: 22.6s\n",
      "57:\tlearn: 0.0142953\ttotal: 1.38s\tremaining: 22.5s\n",
      "58:\tlearn: 0.0141554\ttotal: 1.4s\tremaining: 22.3s\n",
      "59:\tlearn: 0.0140542\ttotal: 1.42s\tremaining: 22.3s\n",
      "60:\tlearn: 0.0139341\ttotal: 1.45s\tremaining: 22.2s\n",
      "61:\tlearn: 0.0138214\ttotal: 1.47s\tremaining: 22.3s\n",
      "62:\tlearn: 0.0137351\ttotal: 1.5s\tremaining: 22.3s\n",
      "63:\tlearn: 0.0136483\ttotal: 1.53s\tremaining: 22.3s\n",
      "64:\tlearn: 0.0135540\ttotal: 1.55s\tremaining: 22.3s\n",
      "65:\tlearn: 0.0135192\ttotal: 1.58s\tremaining: 22.3s\n",
      "66:\tlearn: 0.0134858\ttotal: 1.6s\tremaining: 22.3s\n",
      "67:\tlearn: 0.0134161\ttotal: 1.63s\tremaining: 22.3s\n",
      "68:\tlearn: 0.0133202\ttotal: 1.66s\tremaining: 22.4s\n",
      "69:\tlearn: 0.0132986\ttotal: 1.69s\tremaining: 22.4s\n",
      "70:\tlearn: 0.0131980\ttotal: 1.71s\tremaining: 22.4s\n",
      "71:\tlearn: 0.0131060\ttotal: 1.75s\tremaining: 22.5s\n",
      "72:\tlearn: 0.0130654\ttotal: 1.77s\tremaining: 22.4s\n",
      "73:\tlearn: 0.0130423\ttotal: 1.79s\tremaining: 22.4s\n",
      "74:\tlearn: 0.0129945\ttotal: 1.82s\tremaining: 22.5s\n",
      "75:\tlearn: 0.0128983\ttotal: 1.85s\tremaining: 22.5s\n",
      "76:\tlearn: 0.0128291\ttotal: 1.87s\tremaining: 22.4s\n",
      "77:\tlearn: 0.0126964\ttotal: 1.89s\tremaining: 22.4s\n",
      "78:\tlearn: 0.0126844\ttotal: 1.91s\tremaining: 22.3s\n",
      "79:\tlearn: 0.0126575\ttotal: 1.94s\tremaining: 22.4s\n",
      "80:\tlearn: 0.0126253\ttotal: 1.98s\tremaining: 22.4s\n",
      "81:\tlearn: 0.0125810\ttotal: 2s\tremaining: 22.5s\n",
      "82:\tlearn: 0.0125215\ttotal: 2.04s\tremaining: 22.5s\n",
      "83:\tlearn: 0.0124545\ttotal: 2.06s\tremaining: 22.5s\n",
      "84:\tlearn: 0.0124203\ttotal: 2.1s\tremaining: 22.6s\n",
      "85:\tlearn: 0.0123652\ttotal: 2.13s\tremaining: 22.6s\n",
      "86:\tlearn: 0.0122905\ttotal: 2.15s\tremaining: 22.6s\n",
      "87:\tlearn: 0.0122520\ttotal: 2.19s\tremaining: 22.7s\n",
      "88:\tlearn: 0.0122091\ttotal: 2.22s\tremaining: 22.7s\n",
      "89:\tlearn: 0.0121616\ttotal: 2.26s\tremaining: 22.8s\n",
      "90:\tlearn: 0.0121150\ttotal: 2.28s\tremaining: 22.8s\n",
      "91:\tlearn: 0.0120556\ttotal: 2.31s\tremaining: 22.8s\n",
      "92:\tlearn: 0.0119994\ttotal: 2.34s\tremaining: 22.8s\n",
      "93:\tlearn: 0.0119575\ttotal: 2.37s\tremaining: 22.8s\n",
      "94:\tlearn: 0.0119258\ttotal: 2.4s\tremaining: 22.9s\n",
      "95:\tlearn: 0.0118961\ttotal: 2.43s\tremaining: 22.9s\n",
      "96:\tlearn: 0.0118733\ttotal: 2.47s\tremaining: 23s\n",
      "97:\tlearn: 0.0118389\ttotal: 2.5s\tremaining: 23s\n",
      "98:\tlearn: 0.0117353\ttotal: 2.54s\tremaining: 23.1s\n",
      "99:\tlearn: 0.0116772\ttotal: 2.57s\tremaining: 23.1s\n",
      "100:\tlearn: 0.0116432\ttotal: 2.6s\tremaining: 23.1s\n",
      "101:\tlearn: 0.0115830\ttotal: 2.63s\tremaining: 23.1s\n",
      "102:\tlearn: 0.0115386\ttotal: 2.67s\tremaining: 23.2s\n",
      "103:\tlearn: 0.0114760\ttotal: 2.7s\tremaining: 23.3s\n",
      "104:\tlearn: 0.0114264\ttotal: 2.73s\tremaining: 23.3s\n",
      "105:\tlearn: 0.0113654\ttotal: 2.76s\tremaining: 23.2s\n",
      "106:\tlearn: 0.0113446\ttotal: 2.78s\tremaining: 23.2s\n",
      "107:\tlearn: 0.0113069\ttotal: 2.81s\tremaining: 23.2s\n",
      "108:\tlearn: 0.0112644\ttotal: 2.85s\tremaining: 23.3s\n",
      "109:\tlearn: 0.0112108\ttotal: 2.87s\tremaining: 23.2s\n",
      "110:\tlearn: 0.0111812\ttotal: 2.89s\tremaining: 23.2s\n",
      "111:\tlearn: 0.0111287\ttotal: 2.92s\tremaining: 23.1s\n",
      "112:\tlearn: 0.0111049\ttotal: 2.94s\tremaining: 23.1s\n",
      "113:\tlearn: 0.0110492\ttotal: 2.96s\tremaining: 23s\n",
      "114:\tlearn: 0.0110089\ttotal: 2.99s\tremaining: 23s\n",
      "115:\tlearn: 0.0109812\ttotal: 3.01s\tremaining: 22.9s\n",
      "116:\tlearn: 0.0109599\ttotal: 3.03s\tremaining: 22.9s\n",
      "117:\tlearn: 0.0109188\ttotal: 3.05s\tremaining: 22.8s\n",
      "118:\tlearn: 0.0108640\ttotal: 3.08s\tremaining: 22.8s\n",
      "119:\tlearn: 0.0108471\ttotal: 3.1s\tremaining: 22.7s\n",
      "120:\tlearn: 0.0107926\ttotal: 3.12s\tremaining: 22.7s\n",
      "121:\tlearn: 0.0107826\ttotal: 3.16s\tremaining: 22.7s\n",
      "122:\tlearn: 0.0107474\ttotal: 3.19s\tremaining: 22.7s\n",
      "123:\tlearn: 0.0107224\ttotal: 3.22s\tremaining: 22.7s\n",
      "124:\tlearn: 0.0106875\ttotal: 3.25s\tremaining: 22.7s\n",
      "125:\tlearn: 0.0106363\ttotal: 3.28s\tremaining: 22.7s\n",
      "126:\tlearn: 0.0106080\ttotal: 3.31s\tremaining: 22.8s\n",
      "127:\tlearn: 0.0105800\ttotal: 3.34s\tremaining: 22.7s\n",
      "128:\tlearn: 0.0105481\ttotal: 3.36s\tremaining: 22.7s\n",
      "129:\tlearn: 0.0105187\ttotal: 3.39s\tremaining: 22.7s\n",
      "130:\tlearn: 0.0105037\ttotal: 3.41s\tremaining: 22.7s\n",
      "131:\tlearn: 0.0104588\ttotal: 3.44s\tremaining: 22.6s\n",
      "132:\tlearn: 0.0104085\ttotal: 3.47s\tremaining: 22.6s\n",
      "133:\tlearn: 0.0103744\ttotal: 3.5s\tremaining: 22.6s\n",
      "134:\tlearn: 0.0103520\ttotal: 3.52s\tremaining: 22.6s\n",
      "135:\tlearn: 0.0103225\ttotal: 3.54s\tremaining: 22.5s\n",
      "136:\tlearn: 0.0103006\ttotal: 3.57s\tremaining: 22.5s\n",
      "137:\tlearn: 0.0102795\ttotal: 3.59s\tremaining: 22.4s\n",
      "138:\tlearn: 0.0102221\ttotal: 3.61s\tremaining: 22.4s\n",
      "139:\tlearn: 0.0101947\ttotal: 3.63s\tremaining: 22.3s\n",
      "140:\tlearn: 0.0101650\ttotal: 3.66s\tremaining: 22.3s\n",
      "141:\tlearn: 0.0101419\ttotal: 3.69s\tremaining: 22.3s\n",
      "142:\tlearn: 0.0101160\ttotal: 3.71s\tremaining: 22.3s\n",
      "143:\tlearn: 0.0100831\ttotal: 3.74s\tremaining: 22.2s\n",
      "144:\tlearn: 0.0100165\ttotal: 3.76s\tremaining: 22.2s\n",
      "145:\tlearn: 0.0099975\ttotal: 3.78s\tremaining: 22.1s\n",
      "146:\tlearn: 0.0099858\ttotal: 3.81s\tremaining: 22.1s\n",
      "147:\tlearn: 0.0099544\ttotal: 3.84s\tremaining: 22.1s\n",
      "148:\tlearn: 0.0099432\ttotal: 3.87s\tremaining: 22.1s\n",
      "149:\tlearn: 0.0098862\ttotal: 3.89s\tremaining: 22.1s\n",
      "150:\tlearn: 0.0098451\ttotal: 3.92s\tremaining: 22s\n",
      "151:\tlearn: 0.0098062\ttotal: 3.94s\tremaining: 22s\n",
      "152:\tlearn: 0.0097856\ttotal: 3.96s\tremaining: 21.9s\n",
      "153:\tlearn: 0.0097636\ttotal: 3.99s\tremaining: 21.9s\n",
      "154:\tlearn: 0.0097366\ttotal: 4.02s\tremaining: 21.9s\n",
      "155:\tlearn: 0.0096834\ttotal: 4.04s\tremaining: 21.9s\n",
      "156:\tlearn: 0.0096395\ttotal: 4.06s\tremaining: 21.8s\n",
      "157:\tlearn: 0.0096192\ttotal: 4.08s\tremaining: 21.8s\n",
      "158:\tlearn: 0.0095869\ttotal: 4.1s\tremaining: 21.7s\n",
      "159:\tlearn: 0.0095632\ttotal: 4.13s\tremaining: 21.7s\n",
      "160:\tlearn: 0.0095215\ttotal: 4.16s\tremaining: 21.7s\n",
      "161:\tlearn: 0.0095061\ttotal: 4.19s\tremaining: 21.7s\n",
      "162:\tlearn: 0.0094880\ttotal: 4.22s\tremaining: 21.7s\n",
      "163:\tlearn: 0.0094551\ttotal: 4.25s\tremaining: 21.7s\n",
      "164:\tlearn: 0.0094228\ttotal: 4.28s\tremaining: 21.7s\n",
      "165:\tlearn: 0.0094163\ttotal: 4.32s\tremaining: 21.7s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18244\\2012276513.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_benchmarching\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensembling_top_5_f1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18244\\3086061085.py\u001b[0m in \u001b[0;36mensembling_top_5_f1\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ID\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ID\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\origin\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    670\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m             \u001b[0my_encoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_estimator_has\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\origin\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1471\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1473\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\origin\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;31m# base estimators will be used in transform, predict, and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;31m# predict_proba. They are exposed publicly.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m             self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[0;32m    225\u001b[0m                 \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fit_single_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\origin\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\origin\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[1;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\origin\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\origin\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\origin\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_fit_single_estimator\u001b[1;34m(estimator, X, y, fit_params, message_clsname, message)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\origin\\anaconda3\\Lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5243\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss_function'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5245\u001b[1;33m         self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[0;32m   5246\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5247\u001b[0m                   \u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_snapshot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msnapshot_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msnapshot_interval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_cout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_cerr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\origin\\anaconda3\\Lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Training plots'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m                 self._train(\n\u001b[0m\u001b[0;32m   2411\u001b[0m                     \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m                     \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eval_sets\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\origin\\anaconda3\\Lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_benchmarching.ensembling_top_5_f1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
